FROM gpt-oss:20b

# iGPU-optimized configuration for AMD Vulkan backend
# Addresses excessive token generation on short queries

# Context window - 8K tokens for RAG workloads
PARAMETER num_ctx 8192

# Output limit - prevents runaway generation (critical for short queries)
# Short queries were generating 2000+ tokens, causing 130s latency
PARAMETER num_predict 512

# Low temperature for consistent, focused responses
PARAMETER temperature 0.2

# Batch size optimized for iGPU memory bandwidth
PARAMETER num_batch 512

# Stop tokens to prevent generation beyond expected boundaries
PARAMETER stop "<|end|>"
PARAMETER stop "<|eot_id|>"
PARAMETER stop "<|im_end|>"

# Custom TEMPLATE: Reasoning disabled to fix empty content issue
# gpt-oss Harmony format outputs thinking but leaves content empty when Reasoning is enabled
TEMPLATE """<|start|>system<|message|>You are GPT-OSS, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: {{ currentDate }}

<|end|>
{{- range .Messages }}
{{- if eq .Role "user" }}
<|start|>user<|message|>{{ .Content }}<|end|>
{{- else if eq .Role "assistant" }}
<|start|>assistant<|message|>{{ .Content }}<|end|>
{{- else if eq .Role "system" }}
<|start|>system<|message|>{{ .Content }}<|end|>
{{- end }}
{{- end }}
<|start|>assistant<|message|>"""

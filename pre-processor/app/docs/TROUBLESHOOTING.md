# Logging Troubleshooting Guide

## æ¦‚è¦

Pre-processorã®ãƒ­ã‚®ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã§ç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ä¸€èˆ¬çš„ãªå•é¡Œã¨è§£æ±ºæ–¹æ³•ã‚’ã¾ã¨ã‚ãŸã‚¬ã‚¤ãƒ‰ã§ã™ã€‚

---

## ğŸš¨ ã‚ˆãã‚ã‚‹å•é¡Œ

### 1. fieldsã‚«ãƒ©ãƒ ãŒç©ºã§æŒ¿å…¥ã•ã‚Œã‚‹

#### ç—‡çŠ¶
- ClickHouseã® `fields` ã‚«ãƒ©ãƒ ãŒ `{}` ï¼ˆç©ºã®ãƒãƒƒãƒ—ï¼‰ã«ãªã‚‹
- rask-log-aggregatorã«ãƒ­ã‚°ã¯å±ŠããŒã€ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒæŠ½å‡ºã•ã‚Œãªã„

#### åŸå› 
1. **JSONæ§‹é€ ã®ä¸ä¸€è‡´**: rask-log-forwarderãŒæœŸå¾…ã™ã‚‹slogå½¢å¼ã§ã¯ãªã„
2. **ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãªã—**: æ¨™æº–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆtime, level, msg, serviceï¼‰ã®ã¿ã§ãƒ­ã‚°å‡ºåŠ›
3. **ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã®ç«¶åˆ**: æ¨™æº–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã¨åŒã˜åå‰ã‚’ä½¿ç”¨

#### è§£æ±ºæ–¹æ³•

```go
// âŒ æ‚ªã„ä¾‹ï¼šæ¨™æº–ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿
logger.Info("operation completed")

// âœ… è‰¯ã„ä¾‹ï¼šã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è¿½åŠ 
logger.Info("operation completed", 
    "duration_ms", 150,
    "status", "success",
    "items_processed", 42)
```

#### ç¢ºèªæ–¹æ³•
```sql
-- ClickHouseã§fieldsç¢ºèª
SELECT service_name, message, fields, mapLength(fields) as field_count
FROM logs 
WHERE service_name = 'pre-processor' 
  AND timestamp > now() - INTERVAL 1 HOUR
ORDER BY timestamp DESC 
LIMIT 10;
```

---

### 2. ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œãªã„

#### ç—‡çŠ¶
- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒèµ·å‹•ã™ã‚‹ãŒãƒ­ã‚°ãŒè¡¨ç¤ºã•ã‚Œãªã„
- Docker logsã§ä½•ã‚‚è¡¨ç¤ºã•ã‚Œãªã„

#### åŸå› 
1. **ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š**: DEBUGãƒ­ã‚°ãŒINFOãƒ¬ãƒ™ãƒ«ã§å‡ºåŠ›ã•ã‚Œãªã„
2. **å‡ºåŠ›å…ˆè¨­å®š**: æ¨™æº–å‡ºåŠ›ä»¥å¤–ã«å‡ºåŠ›ã•ã‚Œã¦ã„ã‚‹
3. **ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼**: ãƒ­ã‚¬ãƒ¼ãŒæ­£ã—ãåˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„

#### è§£æ±ºæ–¹æ³•

```go
// 1. ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ç¢ºèª
config := logger.LoadLoggerConfigFromEnv()
fmt.Printf("Log level: %s\n", config.Level) // ãƒ‡ãƒãƒƒã‚°ç”¨å‡ºåŠ›

// 2. å¼·åˆ¶çš„ã«INFOãƒ¬ãƒ™ãƒ«ã§å‡ºåŠ›ãƒ†ã‚¹ãƒˆ
logger.Logger.Info("Logger test - this should appear")

// 3. å‡ºåŠ›å…ˆç¢ºèª
unifiedLogger := logger.NewUnifiedLogger(os.Stdout, "pre-processor") // ç¢ºå®Ÿã«æ¨™æº–å‡ºåŠ›
```

#### ç’°å¢ƒå¤‰æ•°ç¢ºèª
```bash
# Dockerç’°å¢ƒã§ã®ç¢ºèª
docker exec -it pre-processor env | grep LOG

# æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›
LOG_LEVEL=info
SERVICE_NAME=pre-processor
```

---

### 3. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ãŒæ¬ æã™ã‚‹

#### ç—‡çŠ¶
- `request_id`, `trace_id`, `operation` ãŒãƒ­ã‚°ã«å«ã¾ã‚Œãªã„
- åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãŒæ©Ÿèƒ½ã—ãªã„

#### åŸå› 
1. **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨­å®šæ¼ã‚Œ**: WithRequestID()ç­‰ã®å‘¼ã³å‡ºã—å¿˜ã‚Œ
2. **WithContext()æœªä½¿ç”¨**: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œãƒ­ã‚¬ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã„ãªã„
3. **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¼æ’­ã‚¨ãƒ©ãƒ¼**: é–¢æ•°é–“ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒæ­£ã—ãæ¸¡ã•ã‚Œã¦ã„ãªã„

#### è§£æ±ºæ–¹æ³•

```go
// 1. ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨­å®šç¢ºèª
func LoggingMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        requestID := r.Header.Get("X-Request-ID")
        if requestID == "" {
            requestID = generateRequestID()
        }
        
        ctx := logger.WithRequestID(r.Context(), requestID)
        ctx = logger.WithOperation(ctx, "http_request")
        
        // âœ… ç¢ºå®Ÿã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨­å®šã•ã‚ŒãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        next.ServeHTTP(w, r.WithContext(ctx))
    })
}

// 2. ã‚µãƒ¼ãƒ“ã‚¹å±¤ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨ç¢ºèª
func (s *Service) ProcessFeed(ctx context.Context, feedURL string) error {
    // âœ… WithContext()ã‚’ä½¿ç”¨
    contextLogger := s.logger.WithContext(ctx)
    contextLogger.Info("processing started", "feed_url", feedURL)
    
    // âŒ ç›´æ¥ãƒ­ã‚¬ãƒ¼ä½¿ç”¨ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ãªã—ï¼‰
    // s.logger.Info("processing started", "feed_url", feedURL)
}
```

#### ãƒ‡ãƒãƒƒã‚°æ–¹æ³•
```go
// ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå€¤ã®ç¢ºèª
func debugContext(ctx context.Context) {
    if requestID := ctx.Value(logger.RequestIDKey); requestID != nil {
        fmt.Printf("RequestID: %s\n", requestID)
    } else {
        fmt.Println("RequestID not found in context")
    }
    
    if traceID := ctx.Value(logger.TraceIDKey); traceID != nil {
        fmt.Printf("TraceID: %s\n", traceID)
    } else {
        fmt.Println("TraceID not found in context")
    }
}
```

---

### 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹

#### ç—‡çŠ¶
- ãƒ­ã‚°å‡ºåŠ›ãŒé…ã„
- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å¿œç­”æ™‚é–“ãŒæ‚ªåŒ–
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¢—åŠ 

#### åŸå› 
1. **éåº¦ãªãƒ­ã‚°å‡ºåŠ›**: DEBUGãƒ¬ãƒ™ãƒ«ã§å¤§é‡ã®ãƒ­ã‚°
2. **ä¸é©åˆ‡ãªãƒ¬ãƒ™ãƒ«è¨­å®š**: æœ¬ç•ªç’°å¢ƒã§DEBUGãƒ¬ãƒ™ãƒ«
3. **å¤§ããªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ­ã‚°å‡ºåŠ›**: å·¨å¤§ãªstructã‚„sliceã‚’ãƒ­ã‚°å‡ºåŠ›

#### è§£æ±ºæ–¹æ³•

```go
// 1. ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«æœ€é©åŒ–
// æœ¬ç•ªç’°å¢ƒ
LOG_LEVEL=info  // DEBUGã¯é¿ã‘ã‚‹

// é–‹ç™ºç’°å¢ƒ  
LOG_LEVEL=debug // é–‹ç™ºæ™‚ã®ã¿

// 2. æ¡ä»¶ä»˜ããƒ­ã‚°å‡ºåŠ›
if logger.Logger.Enabled(context.Background(), slog.LevelDebug) {
    // é‡ã„å‡¦ç†ã¯DEBUGãƒ¬ãƒ™ãƒ«ãŒæœ‰åŠ¹ãªå ´åˆã®ã¿
    expensiveData := generateExpensiveDebugData()
    logger.Logger.Debug("debug info", "data", expensiveData)
}

// 3. å¤§ããªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯è¦ç´„
// âŒ æ‚ªã„ä¾‹
logger.Info("received request", "full_request", largeRequestObject)

// âœ… è‰¯ã„ä¾‹  
logger.Info("received request", 
    "method", req.Method,
    "path", req.URL.Path,
    "content_length", req.ContentLength)
```

#### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
```go
// ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
func BenchmarkLogging(b *testing.B) {
    logger := logger.NewUnifiedLogger(io.Discard, "test")
    
    b.ResetTimer()
    b.ReportAllocs()
    
    for i := 0; i < b.N; i++ {
        logger.Info("benchmark test", "iteration", i)
    }
}
```

---

### 5. JSONå½¢å¼ã‚¨ãƒ©ãƒ¼

#### ç—‡çŠ¶
- ãƒ­ã‚°ãŒJSONå½¢å¼ã§ãªã„
- rask-log-forwarderãŒãƒ­ã‚°ã‚’è§£æã§ããªã„
- ClickHouseã«ãƒ‡ãƒ¼ã‚¿ãŒæŒ¿å…¥ã•ã‚Œãªã„

#### åŸå› 
1. **textå½¢å¼è¨­å®š**: JSONä»¥å¤–ã®å½¢å¼ã§å‡ºåŠ›
2. **ã‚«ã‚¹ã‚¿ãƒ ãƒãƒ³ãƒ‰ãƒ©ãƒ¼**: slog.NewJSONHandlerä»¥å¤–ä½¿ç”¨
3. **æ”¹è¡Œæ–‡å­—å•é¡Œ**: è¤‡æ•°è¡Œãƒ­ã‚°ã§ JSON ãŒå£Šã‚Œã‚‹

#### è§£æ±ºæ–¹æ³•

```go
// 1. JSONå½¢å¼ç¢ºèª
logger := logger.NewUnifiedLogger(os.Stdout, "pre-processor")

// å‡ºåŠ›ä¾‹ç¢ºèª
logger.Info("test message", "key", "value")
// æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›: {"time":"2024-01-01T12:00:00Z","level":"INFO","msg":"test message","key":"value","service":"pre-processor"}

// 2. æ”¹è¡Œæ–‡å­—ã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†
message := "line1\nline2\nline3"
// âŒ ãã®ã¾ã¾å‡ºåŠ›ã™ã‚‹ã¨JSON ãŒå£Šã‚Œã‚‹
logger.Info(message)

// âœ… ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã¾ãŸã¯è¦ç´„
logger.Info("multiline message", "line_count", 3, "preview", strings.Replace(message, "\n", "\\n", -1))
```

#### JSONæ¤œè¨¼
```bash
# ãƒ­ã‚°å‡ºåŠ›ã®JSONæ¤œè¨¼
docker logs pre-processor 2>&1 | tail -n 1 | jq .

# æˆåŠŸä¾‹
{
  "time": "2024-01-01T12:00:00Z",
  "level": "INFO", 
  "msg": "test message",
  "service": "pre-processor"
}

# ã‚¨ãƒ©ãƒ¼ä¾‹ï¼ˆparse error if invalid JSONï¼‰
parse error: Invalid numeric literal at line 1, column 10
```

---

## ğŸ”§ è¨ºæ–­ã‚³ãƒãƒ³ãƒ‰

### ãƒ­ã‚°å‡ºåŠ›ç¢ºèª
```bash
# 1. æœ€æ–°ã®ãƒ­ã‚°ç¢ºèª
docker logs pre-processor --tail 10

# 2. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ç›£è¦–
docker logs pre-processor -f

# 3. ç‰¹å®šæ™‚é–“ç¯„å›²ã®ãƒ­ã‚°
docker logs pre-processor --since "2024-01-01T10:00:00" --until "2024-01-01T11:00:00"
```

### ClickHouseç¢ºèª
```sql
-- 1. æœ€æ–°ãƒ­ã‚°ç¢ºèª
SELECT * FROM logs 
WHERE service_name = 'pre-processor' 
ORDER BY timestamp DESC 
LIMIT 10;

-- 2. fieldsã‚«ãƒ©ãƒ ç¢ºèª
SELECT service_name, message, fields, mapLength(fields) as field_count
FROM logs 
WHERE service_name = 'pre-processor' 
  AND timestamp > now() - INTERVAL 1 HOUR
  AND mapLength(fields) > 0;

-- 3. ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ
SELECT level, count() as count
FROM logs 
WHERE service_name = 'pre-processor' 
  AND timestamp > now() - INTERVAL 1 HOUR
GROUP BY level;
```

### ã‚³ãƒ³ãƒ†ãƒŠãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
```bash
# 1. ã‚³ãƒ³ãƒ†ãƒŠçŠ¶æ…‹ç¢ºèª
docker ps | grep pre-processor

# 2. rask-log-forwarderç¢ºèª
docker ps | grep rask-log-forwarder

# 3. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¢ºèª
docker network ls
docker network inspect alt-network
```

---

## ğŸš‘ ç·Šæ€¥å¯¾å¿œæ‰‹é †

### 1. ãƒ­ã‚°ãŒå…¨ãå‡ºåŠ›ã•ã‚Œãªã„å ´åˆ

```bash
# Step 1: ã‚³ãƒ³ãƒ†ãƒŠçŠ¶æ…‹ç¢ºèª
docker ps -a | grep pre-processor

# Step 2: å¼·åˆ¶å†èµ·å‹•
docker restart pre-processor

# Step 3: ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ä¸€æ™‚çš„ã«DEBUGã«å¤‰æ›´
docker exec -it pre-processor sh -c 'export LOG_LEVEL=debug'

# Step 4: æ‰‹å‹•ãƒ­ã‚°ãƒ†ã‚¹ãƒˆ
docker exec -it pre-processor sh -c 'echo "Manual test log" >> /proc/1/fd/1'
```

### 2. rask-log-aggregatoré€£æºãŒåœæ­¢ã—ãŸå ´åˆ

```bash
# Step 1: rask-log-forwarderç¢ºèª
docker logs rask-log-forwarder --tail 20

# Step 2: rask-log-aggregatorç¢ºèª  
docker logs rask-log-aggregator --tail 20

# Step 3: æ®µéšçš„å†èµ·å‹•
docker restart rask-log-forwarder
sleep 10
docker restart rask-log-aggregator

# Step 4: æ¥ç¶šç¢ºèª
curl -f http://rask-log-aggregator:9600/health || echo "rask-log-aggregator not responding"
```

### 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã®ç·Šæ€¥å¯¾å¿œ

```bash
# Step 1: ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’ä¸€æ™‚çš„ã«ERRORã«å¤‰æ›´
docker exec -it pre-processor sh -c 'export LOG_LEVEL=error'

# Step 2: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç¢ºèª
docker stats pre-processor --no-stream

# Step 3: å¿…è¦ã«å¿œã˜ã¦ã‚³ãƒ³ãƒ†ãƒŠå†èµ·å‹•
if [[ $(docker stats pre-processor --no-stream --format "{{.MemPerc}}" | sed 's/%//') -gt 80 ]]; then
    echo "High memory usage detected, restarting container"
    docker restart pre-processor
fi
```

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆæ‰‹é †

### ãƒ­ã‚°å‡ºåŠ›ãƒ†ã‚¹ãƒˆ

```go
// 1. åŸºæœ¬ãƒ­ã‚°å‡ºåŠ›ãƒ†ã‚¹ãƒˆ
func TestBasicLogging() {
    logger := logger.NewUnifiedLogger(os.Stdout, "test-service")
    logger.Info("test message", "test_key", "test_value")
    // æœŸå¾…: JSONå½¢å¼ã§å‡ºåŠ›ã•ã‚Œã‚‹
}

// 2. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ­ã‚°ãƒ†ã‚¹ãƒˆ
func TestContextLogging() {
    ctx := logger.WithRequestID(context.Background(), "test-req-123")
    logger := logger.NewUnifiedLogger(os.Stdout, "test-service")
    contextLogger := logger.WithContext(ctx)
    contextLogger.Info("context test")
    // æœŸå¾…: request_idãŒãƒ­ã‚°ã«å«ã¾ã‚Œã‚‹
}
```

### çµ±åˆãƒ†ã‚¹ãƒˆ

```bash
#!/bin/bash
# integration_test.sh

echo "=== Pre-processor Logging Integration Test ==="

# 1. ãƒ­ã‚°å‡ºåŠ›ãƒ†ã‚¹ãƒˆ
echo "1. Testing log output..."
docker exec pre-processor sh -c 'echo "Integration test log" | logger'

# 2. JSONå½¢å¼ç¢ºèª
echo "2. Checking JSON format..."
LOG_LINE=$(docker logs pre-processor --tail 1)
echo "$LOG_LINE" | jq . > /dev/null && echo "âœ… Valid JSON" || echo "âŒ Invalid JSON"

# 3. rask-log-aggregatoré€£æºç¢ºèª
echo "3. Checking rask-log-aggregator integration..."
sleep 5
RECENT_LOGS=$(docker exec clickhouse clickhouse-client --query "SELECT count() FROM logs WHERE service_name = 'pre-processor' AND timestamp > now() - INTERVAL 1 MINUTE")
if [[ $RECENT_LOGS -gt 0 ]]; then
    echo "âœ… Logs reaching ClickHouse: $RECENT_LOGS"
else
    echo "âŒ No recent logs in ClickHouse"
fi

echo "=== Test Complete ==="
```

---

## ğŸ“ ã‚µãƒãƒ¼ãƒˆæƒ…å ±

### ãƒ­ã‚°åé›†
å•é¡Œå ±å‘Šæ™‚ã¯ä»¥ä¸‹ã®æƒ…å ±ã‚’å«ã‚ã¦ãã ã•ã„ï¼š

```bash
# 1. ç’°å¢ƒæƒ…å ±
docker --version
docker-compose --version
echo "SERVICE_NAME: $SERVICE_NAME"
echo "LOG_LEVEL: $LOG_LEVEL"

# 2. ã‚³ãƒ³ãƒ†ãƒŠçŠ¶æ…‹
docker ps -a | grep -E "(pre-processor|rask-log)"

# 3. æœ€æ–°ãƒ­ã‚°
docker logs pre-processor --tail 50
docker logs rask-log-forwarder --tail 20
docker logs rask-log-aggregator --tail 20

# 4. ClickHouseçŠ¶æ…‹
docker exec clickhouse clickhouse-client --query "SELECT count() FROM logs WHERE timestamp > now() - INTERVAL 1 HOUR"
```

### è¨­å®šç¢ºèªãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] `LOG_LEVEL` ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹
- [ ] `SERVICE_NAME` ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹  
- [ ] Docker logsã§JSONå½¢å¼ã®ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã¦ã„ã‚‹
- [ ] rask-log-forwarderã‚³ãƒ³ãƒ†ãƒŠãŒèµ·å‹•ã—ã¦ã„ã‚‹
- [ ] rask-log-aggregatorã‚³ãƒ³ãƒ†ãƒŠãŒèµ·å‹•ã—ã¦ã„ã‚‹
- [ ] ClickHouseã§logsãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ãŒæŒ¿å…¥ã•ã‚Œã¦ã„ã‚‹
- [ ] fieldsã‚«ãƒ©ãƒ ã«ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

```bash
# å®šæœŸç›£è¦–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
#!/bin/bash
while true; do
    MEMORY=$(docker stats pre-processor --no-stream --format "{{.MemPerc}}" | sed 's/%//')
    CPU=$(docker stats pre-processor --no-stream --format "{{.CPUPerc}}" | sed 's/%//')
    
    echo "$(date): Memory: ${MEMORY}%, CPU: ${CPU}%"
    
    if (( $(echo "$MEMORY > 80" | bc -l) )); then
        echo "WARNING: High memory usage detected"
    fi
    
    sleep 60
done
```
FROM python:3.13-slim

# Minimal OS deps (mecab etc. omitted for brevity)
RUN apt-get update && apt-get install -y build-essential && rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY app/pyproject.toml app/uv.lock ./

# Install uv package manager
RUN pip install --no-cache-dir uv

# === install binary wheels ====================================================
# Step 1: Install PyTorch first (CPU-only version from custom index)
RUN uv pip install --system --no-cache-dir torch torchvision torchaudio \
    --index-url https://download.pytorch.org/whl/cpu

# Step 2: Install ML dependencies explicitly before syncing
RUN uv pip install --system --no-cache-dir \
    sentence-transformers>=3.3.0 \
    keybert>=0.8.5 \
    transformers>=4.40.0 \
    scikit-learn>=1.5.2 \
    unidic

# Step 2.5: Download unidic dictionary data
RUN python -m unidic download

# Step 3: Sync core project dependencies
RUN uv sync --locked --no-dev

# Step 4: Install project in editable mode
RUN uv pip install --system --no-cache-dir -e .

# Step 5: Verify ML packages are installed correctly
RUN python -c "import torch; print(f'✅ PyTorch {torch.__version__}')" && \
    python -c "import sentence_transformers; print(f'✅ SentenceTransformers {sentence_transformers.__version__}')" && \
    python -c "import keybert; print('✅ KeyBERT installed')" && \
    python -c "import transformers; print(f'✅ Transformers {transformers.__version__}')"

# Optional: pre‑cache the SBERT model and download NLTK data
RUN python - <<'PY'
import nltk
from sentence_transformers import SentenceTransformer

# Download NLTK data
nltk.download('punkt_tab', quiet=True)
nltk.download('stopwords', quiet=True)
print('✅ NLTK data downloaded')

# Cache SBERT model
SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device='cpu')
print('✅ SBERT model cached')
PY

COPY app/ .
CMD ["python", "main.py"]

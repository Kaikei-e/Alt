networks:
  alt-network:

volumes:
  db_data:
  meili_data:
  rask_log_aggregator_data:

x-rask-env: &rask-env
  environment:
    RASK_CONFIG: |
      endpoint = "http://rask-log-aggregator:9600/v1/aggregate"
      batch_size = 1
      flush_interval_ms = 500
      buffer_capacity = 100000
      log_level = "info"

services:
  nginx:
    image: nginx:latest
    restart: unless-stopped
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
    depends_on:
      alt-frontend:
        condition: service_healthy
      alt-backend:
        condition: service_healthy
    networks:
      - alt-network
    # Resource limits for better performance
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    # Increase file descriptor limits
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    tty: true
    labels:
      - rask.group=alt-frontend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  alt-frontend:
    build:
      context: ./alt-frontend
      dockerfile: Dockerfile.frontend
      x-bake: &buildkit
        platforms: ["linux/amd64"]
      args:
        - NEXT_PUBLIC_API_BASE_URL=/api
        - API_URL=http://alt-backend:9000
    environment:
      - NEXT_PUBLIC_API_BASE_URL=/api
      - API_URL=http://alt-backend:9000
      - NODE_ENV=production
      - PORT=3000
    ports:
      - "3000:3000"
    restart: unless-stopped
    networks:
      - alt-network
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    tty: true
    labels:
      - rask.group=alt-frontend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  alt-backend:
    build:
      context: ./alt-backend
      dockerfile: Dockerfile.backend
    restart: unless-stopped
    ports:
      - "9000:9000"
    networks:
      - alt-network
    volumes:
      - .env:/app/.env
    environment:
      - DB_HOST=db
      - DB_PORT=5432
      - DB_USER=${POSTGRES_USER}
      - DB_PASSWORD=${POSTGRES_PASSWORD}
      - DB_NAME=${POSTGRES_DB}
    depends_on:
      db:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    # Resource limits for backend
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '4.0'
        reservations:
          memory: 2G
          cpus: '2.0'
    # Increase file descriptor limits for backend
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:9000/v1/health || exit 1"]
      interval: 20s
      timeout: 10s
      retries: 5
      start_period: 60s
    tty: true
    labels:
      - rask.group=alt-backend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  news-creator:
    build:
      context: ./news-creator
      dockerfile: Dockerfile.creator
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ./news-creator/models:/root/.ollama/models
    restart: unless-stopped
    ports:
      - "11434:11434"
    networks:
      - alt-network
    healthcheck:
      test: ["CMD-SHELL", "curl http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 60s
    tty: true
    labels:
      - rask.group=alt-backend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  pre-processor:
    build:
      context: ./pre-processor
      dockerfile: Dockerfile.preprocess
    environment:
      - DB_HOST=db
      - DB_PORT=5432
      - DB_NAME=${DB_NAME}
      - PRE_PROCESSOR_DB_USER=${PRE_PROCESSOR_DB_USER}
      - PRE_PROCESSOR_DB_PASSWORD=${PRE_PROCESSOR_DB_PASSWORD}
    depends_on:
      db:
        condition: service_healthy
      news-creator:
        condition: service_healthy
    restart: always
    ports:
      - "9200:9200"
    networks:
      - alt-network
    tty: true
    labels:
      - rask.group=alt-backend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  search-indexer:
    build:
      context: ./search-indexer
      dockerfile: Dockerfile.search-indexer
    environment:
      - DB_HOST=db
      - DB_PORT=5432
      - DB_NAME=${DB_NAME}
      - SEARCH_INDEXER_DB_USER=${SEARCH_INDEXER_DB_USER}
      - SEARCH_INDEXER_DB_PASSWORD=${SEARCH_INDEXER_DB_PASSWORD}
      - MEILISEARCH_HOST=${MEILISEARCH_HOST}
      - MEILISEARCH_API_KEY=${MEILI_MASTER_KEY}
    depends_on:
      db:
        condition: service_healthy
      meilisearch:
        condition: service_healthy
    networks:
      - alt-network
    ports:
      - "9300:9300"
    tty: true
    labels:
      - rask.group=alt-backend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  tag-generator:
    build:
      context: ./tag-generator
      dockerfile: Dockerfile.tag-generator
    networks:
      - alt-network
    ports:
      - "9400:9400"
    environment:
      - DB_HOST=db
      - DB_PORT=5432
      - DB_NAME=${DB_NAME}
      - DB_TAG_GENERATOR_USER=${DB_TAG_GENERATOR_USER}
      - DB_TAG_GENERATOR_PASSWORD=${DB_TAG_GENERATOR_PASSWORD}
      # Force CPU-only to prevent GPU memory issues
      - CUDA_VISIBLE_DEVICES=""
    tty: true
    depends_on:
      db:
        condition: service_healthy
    restart: unless-stopped
    labels:
      - rask.group=alt-backend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  meilisearch:
      image: getmeili/meilisearch:v1.6
      restart: unless-stopped
      environment:
        MEILI_MASTER_KEY: ${MEILI_MASTER_KEY}
        MEILI_ENV: "production"
      ports:
        - "7700:7700"
      volumes:
        - meili_data:/meili_data   # persistent index storage
      networks:
        - alt-network
      healthcheck:
        test: ["CMD", "curl", "-f", "http://localhost:7700/health"]
        interval: 10s
        timeout: 5s
        retries: 5
      deploy:
        resources:
          limits:
            memory: 4G
          reservations:
            memory: 2G
      tty: true
      labels:
        - rask.group=alt-backend
      logging:
        driver: "json-file"
        options:
          max-size: "10m"
          max-file: "3"
  rask-log-aggregator:
    build:
      context: ./rask-log-aggregator
      dockerfile: Dockerfile.rask-log-aggregator
    restart: unless-stopped
    ports:
      - "9600:9600"
    networks:
      - alt-network
    tty: true
    volumes:
      - ./rask-log-aggregator/logs:/logs
    labels:
      - rask.group=alt-backend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  db:
    image: postgres:16-alpine
    restart: always
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      DB_HOST: ${DB_HOST}
      DB_PORT: ${DB_PORT}
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: ${DB_NAME}
      PRE_PROCESSOR_DB_USER: ${PRE_PROCESSOR_DB_USER}
      PRE_PROCESSOR_DB_PASSWORD: ${PRE_PROCESSOR_DB_PASSWORD}
      DB_TAG_GENERATOR_USER: ${DB_TAG_GENERATOR_USER}
      DB_TAG_GENERATOR_PASSWORD: ${DB_TAG_GENERATOR_PASSWORD}
      SEARCH_INDEXER_DB_USER: ${SEARCH_INDEXER_DB_USER}
      SEARCH_INDEXER_DB_PASSWORD: ${SEARCH_INDEXER_DB_PASSWORD}
    volumes:
      - db_data:/var/lib/postgresql/data
      - ./db/init:/docker-entrypoint-initdb.d:rw
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - alt-network
    tty: true
    labels:
      - rask.group=alt-backend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  migrate:
    build:
      context: ./migrate
      dockerfile: Dockerfile.migrate
    container_name: db_migrator
    volumes:
      - ./db/migrations:/migrations
      - ./db/postgresql.conf:/etc/postgresql/postgresql.conf
    environment:
      DB_URL: "pgx5://${POSTGRES_USER:-devuser}:${POSTGRES_PASSWORD:-devpassword}@db:5432/${POSTGRES_DB:-devdb}?sslmode=disable&search_path=public"
      MIGRATE_MAX_RETRIES: "12"
      MIGRATE_RETRY_INTERVAL: "5"
    depends_on:
      db:
        condition: service_healthy
    networks:
      - alt-network

################### For Rask Log Aggregator ###################
  nginx-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:nginx"
    <<: *rask-env
    environment:
      TARGET_SERVICE: "${NGINX_TARGET:-nginx}"
      DOCKER_HOST: "unix:///var/run/docker.sock"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    group_add:
      - "${DOCKER_GROUP_ID:-984}"  # docker group (fallback to 984)
    restart: unless-stopped
    profiles:
      - logging

  alt-frontend-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:alt-frontend"
    <<: *rask-env
    environment:
      TARGET_SERVICE: "${ALT_FRONTEND_TARGET:-alt-frontend}"
      DOCKER_HOST: "unix:///var/run/docker.sock"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    group_add:
      - "${DOCKER_GROUP_ID:-984}"  # docker group (fallback to 984)
    restart: unless-stopped
    profiles:
      - logging

  alt-backend-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:alt-backend"
    <<: *rask-env
    environment:
      TARGET_SERVICE: "${ALT_BACKEND_TARGET:-alt-backend}"
      DOCKER_HOST: "unix:///var/run/docker.sock"
      LOG_LEVEL: "info"
      RUST_LOG: "info"
      RASK_ENDPOINT: "http://rask-log-aggregator:9600/v1/aggregate"
      BATCH_SIZE: "1000"
      FLUSH_INTERVAL_MS: "500"
      BUFFER_CAPACITY: "100000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    group_add:
      - "${DOCKER_GROUP_ID:-984}"  # docker group (fallback to 984)
    restart: unless-stopped
    profiles:
      - logging

  tag-generator-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:tag-generator"
    <<: *rask-env
    environment:
      TARGET_SERVICE: "tag-generator"
      DOCKER_HOST: "unix:///var/run/docker.sock"
      LOG_LEVEL: "info"
      BATCH_SIZE: "1000"
      FLUSH_INTERVAL_MS: "500"
      BUFFER_CAPACITY: "100000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    group_add:
      - "${DOCKER_GROUP_ID:-984}"  # docker group (fallback to 984)
    restart: unless-stopped
    profiles:
      - logging

  pre-processor-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:pre-processor"
    <<: *rask-env
    environment:
      TARGET_SERVICE: "pre-processor"
      DOCKER_HOST: "unix:///var/run/docker.sock"
      LOG_LEVEL: "info"
      BATCH_SIZE: "1000"
      FLUSH_INTERVAL_MS: "500"
      BUFFER_CAPACITY: "100000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    group_add:
      - "${DOCKER_GROUP_ID:-984}"  # docker group (fallback to 984)
    restart: unless-stopped
    profiles:
      - logging

  search-indexer-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:search-indexer"
    <<: *rask-env
    environment:
      TARGET_SERVICE: "search-indexer"
      DOCKER_HOST: "unix:///var/run/docker.sock"
      LOG_LEVEL: "info"
      BATCH_SIZE: "1000"
      FLUSH_INTERVAL_MS: "500"
      BUFFER_CAPACITY: "100000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    group_add:
      - "${DOCKER_GROUP_ID:-984}"  # docker group (fallback to 984)
    restart: unless-stopped
    profiles:
      - logging

  news-creator-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:news-creator"
    <<: *rask-env
    environment:
      TARGET_SERVICE: "news-creator"
      DOCKER_HOST: "unix:///var/run/docker.sock"
      LOG_LEVEL: "info"
      BATCH_SIZE: "1000"
      FLUSH_INTERVAL_MS: "500"
      BUFFER_CAPACITY: "100000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    group_add:
      - "${DOCKER_GROUP_ID:-984}"  # docker group (fallback to 984)
    restart: unless-stopped
    profiles:
      - logging

  meilisearch-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:meilisearch"
    <<: *rask-env
    environment:
      TARGET_SERVICE: "meilisearch"
      DOCKER_HOST: "unix:///var/run/docker.sock"
      LOG_LEVEL: "info"
      BATCH_SIZE: "1000"
      FLUSH_INTERVAL_MS: "500"
      BUFFER_CAPACITY: "100000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    restart: unless-stopped
    profiles:
      - logging

  db-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:db"
    <<: *rask-env
    environment:
      TARGET_SERVICE: "db"
      DOCKER_HOST: "unix:///var/run/docker.sock"
      LOG_LEVEL: "info"
      BATCH_SIZE: "1000"
      FLUSH_INTERVAL_MS: "500"
      BUFFER_CAPACITY: "100000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    restart: unless-stopped
    profiles:
      - logging


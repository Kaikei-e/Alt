# ALT Platform Docker Compose Configuration
#
# Changes made:
# - Updated pre-processor to use multi-stage Dockerfile with pre-compiled Go binary
# - Added comments for volume definitions
# - Aligned with Kubernetes deployment configuration
#
# Usage:
#   docker-compose up -d                    # Start all services
#   docker-compose up -d --profile logging  # Start with logging services
#   docker-compose down --profile logging   # Stop with logging services
#

secrets:
  auth_shared_secret:
    file: ./secrets/auth_shared_secret.txt
  backend_token_secret:
    file: ./secrets/backend_token_secret.txt
  postgres_password:
    file: ./secrets/postgres_password.txt
  db_password:
    file: ./secrets/db_password.txt
  pre_processor_db_password:
    file: ./secrets/pre_processor_db_password.txt
  tag_generator_db_password:
    file: ./secrets/tag_generator_db_password.txt
  search_indexer_db_password:
    file: ./secrets/search_indexer_db_password.txt
  recap_db_password:
    file: ./secrets/recap_db_password.txt
  kratos_db_password:
    file: ./secrets/kratos_db_password.txt
  kratos_cookie_secret:
    file: ./secrets/kratos_cookie_secret.txt
  kratos_cipher_secret:
    file: ./secrets/kratos_cipher_secret.txt
  meili_master_key:
    file: ./secrets/meili_master_key.txt
  clickhouse_password:
    file: ./secrets/clickhouse_password.txt
  csrf_secret:
    file: ./secrets/csrf_secret.txt
  service_secret:
    file: ./secrets/service_secret.txt
  hugging_face_token:
    file: ./secrets/hugging_face_token.txt

networks:
  alt-network:

volumes:
  # Persistent storage volumes for data persistence
  # NOTE: db_data (PostgreSQL 16) is no longer used - removed to save memory
  # If you need to clean up old volumes, run: make docker-remove-old-volumes
  db_data_17:                 # PostgreSQL 17 database data (current production)
  kratos_db_data:             # Kratos PostgreSQL database data
  meili_data:                 # MeiliSearch index data
  rask_log_aggregator_data:   # Rask log aggregator data
  clickhouse_data:            # ClickHouse database data
  news_creator_models:        # Ollama models for news-creator
  recap_db_data:              # Recap Worker PostgreSQL database data
x-rask-env: &rask-env
  environment:
    RASK_CONFIG: |
      endpoint = "http://rask-log-aggregator:9600/v1/aggregate"
      batch_size = 1
      flush_interval_ms = 500
      buffer_capacity = 100000
      log_level = "info"

x-rask-forwarder-env: &rask-forwarder-env
  environment:
    DOCKER_HOST: "unix:///var/run/docker.sock"
    LOG_LEVEL: "info"
    RUST_LOG: "info"
    RASK_ENDPOINT: "http://rask-log-aggregator:9600/v1/aggregate"
    BATCH_SIZE: "1000"
    FLUSH_INTERVAL_MS: "500"
    BUFFER_CAPACITY: "100000"

x-shared-env-file: &shared-env-file
  env_file:
    - .env

services:
  nginx:
    image: nginx:latest
    restart: always
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:rw
      - ./nginx/docker-entrypoint.d:/docker-entrypoint.d:ro
    secrets:
      - auth_shared_secret
    depends_on:
      alt-frontend:
        condition: service_healthy
      alt-backend:
        condition: service_healthy
      kratos:
        condition: service_healthy
      auth-hub:
        condition: service_started
    networks:
      - alt-network
    # Resource limits for better performance
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    # Increase file descriptor limits
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    tty: true
    labels:
      - rask.group=alt-frontend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  alt-frontend:
    <<: *shared-env-file
    build:
      context: ./alt-frontend
      dockerfile: Dockerfile.frontend
      x-bake: &buildkit
        platforms: ["linux/amd64"]
      args:
        - NEXT_PUBLIC_API_BASE_URL=/api
        - API_URL=http://alt-backend:9000
        - NEXT_PUBLIC_IDP_ORIGIN=${NEXT_PUBLIC_IDP_ORIGIN}
        - NEXT_PUBLIC_KRATOS_PUBLIC_URL=${NEXT_PUBLIC_KRATOS_PUBLIC_URL}
        - NEXT_PUBLIC_APP_ORIGIN=${NEXT_PUBLIC_APP_ORIGIN}
        - NEXT_PUBLIC_RETURN_TO_DEFAULT=${NEXT_PUBLIC_RETURN_TO_DEFAULT}
        - KRATOS_INTERNAL_URL=${KRATOS_INTERNAL_URL}
        - KRATOS_PUBLIC_URL=${KRATOS_PUBLIC_URL}
    environment:
      - NEXT_PUBLIC_API_BASE_URL=/api
      - API_URL=http://alt-backend:9000
      - NEXT_PUBLIC_APP_ORIGIN=${NEXT_PUBLIC_APP_ORIGIN}
      - NEXT_PUBLIC_RETURN_TO_DEFAULT=${NEXT_PUBLIC_RETURN_TO_DEFAULT}
      - KRATOS_INTERNAL_URL=${KRATOS_INTERNAL_URL}
      - KRATOS_PUBLIC_URL=${KRATOS_PUBLIC_URL}
      - AUTH_HUB_INTERNAL_URL=${AUTH_HUB_INTERNAL_URL}
      - NODE_ENV=production
      - PORT=3000
    ports:
      - "3000:3000"
    restart: always
    networks:
      - alt-network
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://127.0.0.1:3000/api/health | grep -q '\"status\":\"ok\"' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    tty: true

  alt-frontend-sv:
    <<: *shared-env-file
    build:
      context: ./alt-frontend-sv
      dockerfile: Dockerfile
    environment:
      - PORT=4173
      - ORIGIN=${ORIGIN:-http://localhost:4173}
      - BODY_SIZE_LIMIT=Infinity
      - KRATOS_INTERNAL_URL=${KRATOS_INTERNAL_URL:-http://kratos:4433}
      - KRATOS_PUBLIC_URL=${KRATOS_PUBLIC_URL:-http://localhost/ory}
      - PUBLIC_API_BASE_URL=${PUBLIC_API_BASE_URL:-http://localhost:9000}
      - BACKEND_BASE_URL=${BACKEND_BASE_URL:-http://alt-backend:9000}
      - AUTH_HUB_INTERNAL_URL=${AUTH_HUB_INTERNAL_URL:-http://auth-hub:8888}
    ports:
      - "4173:4173"
    restart: always
    networks:
      - alt-network
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    tty: true
    labels:
      - rask.group=alt-frontend-sv
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  alt-backend:
    <<: *shared-env-file
    build:
      context: ./alt-backend
      dockerfile: Dockerfile.backend
    restart: always
    ports:
      - "9000:9000"
    networks:
      - alt-network
    volumes:
      - .env:/app/.env
    environment:
      - DB_HOST=db  # PostgreSQL 17 (final)
      - DB_PORT=5432
      - DB_USER=${DB_USER}
      - DB_PASSWORD_FILE=/run/secrets/db_password
      - DB_NAME=${POSTGRES_DB}
      - DB_SSL_MODE=prefer
      - CSRF_SECRET_FILE=/run/secrets/csrf_secret
      - SERVICE_SECRET_FILE=/run/secrets/service_secret
      - AUTH_SHARED_SECRET_FILE=/run/secrets/auth_shared_secret
      - BACKEND_TOKEN_SECRET_FILE=/run/secrets/backend_token_secret
      - BACKEND_TOKEN_ISSUER=auth-hub
      - BACKEND_TOKEN_AUDIENCE=alt-backend
    secrets:
      - auth_shared_secret
      - backend_token_secret
      - db_password
      - csrf_secret
      - service_secret
    depends_on:
      db:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    # Resource limits for backend
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '4.0'
        reservations:
          memory: 2G
          cpus: '2.0'
    # Increase file descriptor limits for backend
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:9000/v1/health || exit 1"]
      interval: 20s
      timeout: 10s
      retries: 5
      start_period: 60s
    tty: true
    labels:
      - rask.group=alt-backend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  news-creator:
    profiles:
      - ollama
    <<: *shared-env-file
    build:
      context: ./news-creator
      dockerfile: Dockerfile.creator
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - OLLAMA_HOME=/home/ollama-user/.ollama
      - OLLAMA_MODELS=/home/ollama-user/.ollama
      - LLM_SERVICE_URL=${LLM_SERVICE_URL:-http://127.0.0.1:11435}
      - LLM_NUM_PREDICT=${LLM_NUM_PREDICT:-1200}
      - SUMMARY_NUM_PREDICT=${SUMMARY_NUM_PREDICT:-500}
      - SERVICE_SECRET_FILE=/run/secrets/service_secret
    secrets:
      - service_secret
    volumes:
      - news_creator_models:/home/ollama-user/.ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    networks:
      - alt-network
    depends_on:
      news-creator-volume-init:
        condition: service_completed_successfully
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 60s
    labels:
      - rask.group=news-creator
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  news-creator-volume-init:
    profiles:
      - ollama
    build:
      context: ./news-creator
      dockerfile: Dockerfile.creator
    entrypoint: ["/bin/sh", "-c"]
    command: ["chown -R 2000:2000 /home/ollama-user/.ollama"]
    user: "0:0"
    volumes:
      - news_creator_models:/home/ollama-user/.ollama
    networks:
      - alt-network
    restart: "no"
    labels:
      - rask.group=news-creator-init

  pre-processor:
    profiles:
      - ollama
    <<: *shared-env-file
    # Updated to use multi-stage build with pre-compiled Go binary
    build:
      context: ./pre-processor
      dockerfile: Dockerfile
    environment:
      - DB_HOST=db  # PostgreSQL 17 (final)
      - DB_PORT=5432
      - DB_NAME=${DB_NAME}
      - PRE_PROCESSOR_DB_USER=${PRE_PROCESSOR_DB_USER}
      - PRE_PROCESSOR_DB_PASSWORD_FILE=/run/secrets/pre_processor_db_password
      - DB_SSL_MODE=prefer
      - LOG_LEVEL=info
      - SERVICE_NAME=pre-processor
    secrets:
      - pre_processor_db_password
    depends_on:
      db:
        condition: service_healthy
      news-creator:
        condition: service_healthy
    restart: always
    ports:
      - "9200:9200"
    networks:
      - alt-network
    tty: true
    labels:
      - rask.group=pre-processor
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  search-indexer:
    <<: *shared-env-file
    build:
      context: ./search-indexer
      dockerfile: Dockerfile.search-indexer
    environment:
      - DB_HOST=db  # PostgreSQL 17 (final)
      - DB_PORT=5432
      - DB_NAME=${DB_NAME}
      - DB_SSL_MODE=prefer
      - SEARCH_INDEXER_DB_USER=${SEARCH_INDEXER_DB_USER}
      - SEARCH_INDEXER_DB_PASSWORD_FILE=/run/secrets/search_indexer_db_password
      - MEILISEARCH_HOST=${MEILISEARCH_HOST}
      - MEILISEARCH_API_KEY_FILE=/run/secrets/meili_master_key
      - MEILI_MASTER_KEY_FILE=/run/secrets/meili_master_key
    secrets:
      - search_indexer_db_password
      - meili_master_key
    depends_on:
      db:
        condition: service_healthy
      meilisearch:
        condition: service_healthy
    networks:
      - alt-network
    ports:
      - "9300:9300"
    tty: true
    labels:
      - rask.group=search-indexer
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  tag-generator:
    <<: *shared-env-file
    build:
      context: ./tag-generator
      dockerfile: Dockerfile.tag-generator
    networks:
      - alt-network
    ports:
      - "9400:9400"
    environment:
      - DB_HOST=db  # PostgreSQL 17 (final)
      - DB_PORT=5432
      - DB_NAME=${DB_NAME}
      - DB_TAG_GENERATOR_USER=${DB_TAG_GENERATOR_USER}
      - DB_TAG_GENERATOR_PASSWORD_FILE=/run/secrets/tag_generator_db_password
      - PORT=9400
      - SERVICE_SECRET_FILE=/run/secrets/service_secret
      # Force CPU-only to prevent GPU memory issues
      - CUDA_VISIBLE_DEVICES=""
    secrets:
      - tag_generator_db_password
      - service_secret
    volumes:
      - ./scripts:/scripts:ro
      - ./tag-generator/models/onnx:/models/onnx:ro
    tty: true
    depends_on:
      db:
        condition: service_healthy
    restart: unless-stopped
    labels:
      - rask.group=tag-generator
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  recap-worker:
    <<: *shared-env-file
    build:
      context: ./recap-worker
      dockerfile: Dockerfile.recap-worker
    profiles:
      - recap
    networks:
      - alt-network
    environment:
      - DATABASE_URL=postgres://${RECAP_DB_USER}:${RECAP_DB_PASSWORD}@recap-db:${RECAP_DB_PORT}/${RECAP_DB_NAME}
      - RECAP_DB_DSN=${RECAP_DB_DSN}
      - RECAP_DB_HOST=recap-db
      - RECAP_DB_PORT=${RECAP_DB_PORT}
      - RECAP_DB_USER=${RECAP_DB_USER}
      - RECAP_DB_PASSWORD_FILE=/run/secrets/recap_db_password
      - RECAP_DB_NAME=${RECAP_DB_NAME}
      - NEWS_CREATOR_BASE_URL=http://news-creator:11434
      - SUBWORKER_BASE_URL=http://recap-subworker:8002
      - ALT_BACKEND_BASE_URL=${ALT_BACKEND_BASE_URL}
      - ALT_BACKEND_SERVICE_TOKEN_FILE=/run/secrets/service_secret
      - TAG_LABEL_GRAPH_WINDOW=${TAG_LABEL_GRAPH_WINDOW}
      - TAG_LABEL_GRAPH_TTL_SECONDS=${TAG_LABEL_GRAPH_TTL_SECONDS}
      - HUGGING_FACE_TOKEN_PATH=/run/secrets/hugging_face_token
    secrets:
      - recap_db_password
      - service_secret
      - hugging_face_token
    depends_on:
      recap-db:
        condition: service_healthy
    restart: unless-stopped
    ports:
      - "9005:9005"
    labels:
      - rask.group=recap-worker
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  recap-subworker:
    <<: *shared-env-file
    build:
      context: ./recap-subworker
      dockerfile: Dockerfile.recap-subworker
    profiles:
      - recap
    networks:
      - alt-network
    environment:
      - RECAP_SUBWORKER_DB_PASSWORD_FILE=/run/secrets/recap_db_password
      - RECAP_SUBWORKER_BASE_URL=http://recap-subworker:8002
      - RECAP_SUBWORKER_MODEL_BACKEND=sentence-transformers
      - RECAP_SUBWORKER_MODEL_ID=intfloat/multilingual-e5-large
      - RECAP_SUBWORKER_PIPELINE_MODE=processpool
      - RECAP_SUBWORKER_GUNICORN_WORKER_TIMEOUT=900
    ports:
      - "8002:8002"
    secrets:
      - recap_db_password
    volumes:
      # Share golden dataset from recap-worker
      - ./recap-worker/recap-worker/tests/data/golden_classification.json:/app/data/golden_classification.json:ro
      # Mount trained genre classifier
      - ./recap-subworker/data/genre_classifier.joblib:/app/data/genre_classifier.joblib:ro
    depends_on:
      recap-worker:
        condition: service_started
    restart: unless-stopped
    labels:
      - rask.group=recap-subworker
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  meilisearch:
      image: getmeili/meilisearch:v1.27.0
      restart: unless-stopped
      command: sh -c "export MEILI_MASTER_KEY=$$(cat /run/secrets/meili_master_key) && meilisearch"
      environment:
        MEILI_ENV: "production"
      secrets:
        - meili_master_key
      ports:
        - "7700:7700"
      volumes:
        - meili_data:/meili_data   # persistent index storage
      networks:
        - alt-network
      healthcheck:
        test: ["CMD", "curl", "-f", "http://localhost:7700/health"]
        interval: 10s
        timeout: 5s
        retries: 5
      deploy:
        resources:
          limits:
            memory: 15G
          reservations:
            memory: 8G
      tty: true
      labels:
        - rask.group=meilisearch
      logging:
        driver: "json-file"
        options:
          max-size: "10m"
          max-file: "3"
  rask-log-aggregator:
    build:
      context: ./rask-log-aggregator
      dockerfile: Dockerfile.rask-log-aggregator
    restart: unless-stopped
    ports:
      - "9600:9600"
    networks:
      - alt-network
    tty: true
    labels:
      - rask.group=rask-log-aggregator
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    depends_on:
      clickhouse:
        condition: service_healthy
    environment:
      APP_CLICKHOUSE_HOST: clickhouse
      APP_CLICKHOUSE_PORT: 8123
      APP_CLICKHOUSE_USER: ${CLICKHOUSE_USER}
      APP_CLICKHOUSE_PASSWORD_FILE: /run/secrets/clickhouse_password
      APP_CLICKHOUSE_DATABASE: ${CLICKHOUSE_DB}
    secrets:
      - clickhouse_password
  clickhouse:
    image: clickhouse/clickhouse-server:25.9
    restart: unless-stopped
    environment:
      CLICKHOUSE_DB: ${CLICKHOUSE_DB:-rask_logs}
      CLICKHOUSE_USER: ${CLICKHOUSE_USER:-rask_user}
      CLICKHOUSE_PASSWORD_FILE: /run/secrets/clickhouse_password
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    secrets:
      - clickhouse_password
    ports:
      - "8123:8123"
      - "9009:9000"
    volumes:
      - ./clickhouse/init:/docker-entrypoint-initdb.d
      - clickhouse_data:/var/lib/clickhouse
    networks:
      - alt-network
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8123/ping"]
      interval: 10s
      timeout: 5s
      retries: 3
  # === PostgreSQL 17 (Production) ===
  db:
    image: postgres:17-alpine
    container_name: alt-db
    restart: always
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c hba_file=/etc/postgresql/pg_hba.conf
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password
      DB_HOST: ${DB_HOST}
      DB_PORT: ${DB_PORT}
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: ${DB_NAME}
      PRE_PROCESSOR_DB_USER: ${PRE_PROCESSOR_DB_USER}
      PRE_PROCESSOR_DB_PASSWORD: ${PRE_PROCESSOR_DB_PASSWORD}
      DB_TAG_GENERATOR_USER: ${DB_TAG_GENERATOR_USER}
      DB_TAG_GENERATOR_PASSWORD: ${DB_TAG_GENERATOR_PASSWORD}
      SEARCH_INDEXER_DB_USER: ${SEARCH_INDEXER_DB_USER}
      SEARCH_INDEXER_DB_PASSWORD_FILE: /run/secrets/search_indexer_db_password
    secrets:
      - postgres_password
      - pre_processor_db_password
      - tag_generator_db_password
      - search_indexer_db_password
    volumes:
      - db_data_17:/var/lib/postgresql/data  # PostgreSQL 17 production data
      - ./db/init:/docker-entrypoint-initdb.d:rw
      - ./docker/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./docker/postgres/pg_hba.conf:/etc/postgresql/pg_hba.conf:ro
    ports:
      - "5432:5432"  # Production PostgreSQL 17 port
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - alt-network
    tty: true
    labels:
      - rask.group=db
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Backward compatibility alias - REMOVED (now db is PostgreSQL 17)

  kratos-db:
    image: postgres:16-alpine
    restart: always
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c hba_file=/etc/postgresql/pg_hba.conf
    environment:
      POSTGRES_DB: ${KRATOS_DB_NAME:-kratos}
      POSTGRES_USER: ${KRATOS_DB_USER:-kratos_user}
      POSTGRES_PASSWORD_FILE: /run/secrets/kratos_db_password
    secrets:
      - kratos_db_password
    volumes:
      - kratos_db_data:/var/lib/postgresql/data
      - ./kratos-db/init:/docker-entrypoint-initdb.d:rw
      - ./docker/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./docker/postgres/pg_hba.conf:/etc/postgresql/pg_hba.conf:ro
    ports:
      - "5434:5432"  # Changed from 5433 due to db-pg17 using 5433
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${KRATOS_DB_USER:-kratos_user} -d ${KRATOS_DB_NAME:-kratos}"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - alt-network
    tty: true
    labels:
      - rask.group=kratos-db
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # === Recap Worker PostgreSQL 18 ===
  recap-db:
    image: postgres:18-alpine
    container_name: recap-db
    profiles:
      - recap
    restart: always
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c hba_file=/etc/postgresql/pg_hba.conf
    environment:
      POSTGRES_DB: ${RECAP_DB_NAME}
      POSTGRES_USER: ${RECAP_DB_USER}
      POSTGRES_PASSWORD_FILE: /run/secrets/recap_db_password
    secrets:
      - recap_db_password
    volumes:
      - recap_db_data:/var/lib/postgresql/data
      - ./recap-worker/recap-db/init:/docker-entrypoint-initdb.d:rw
      - ./docker/postgres/postgresql-recap.conf:/etc/postgresql/postgresql.conf:ro
      - ./docker/postgres/pg_hba.conf:/etc/postgresql/pg_hba.conf:ro
    ports:
      - "5435:5432" # Using a different port to avoid conflict
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${RECAP_DB_USER} -d ${RECAP_DB_NAME}"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - alt-network
    tty: true
    labels:
      - rask.group=recap-db
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  migrate:
    <<: *shared-env-file
    build:
      context: ./migrations-atlas
      dockerfile: docker/Dockerfile
    container_name: db_migrator
    command: ["apply"]
    environment:
      DATABASE_URL: "postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}?sslmode=disable&search_path=public"
      MIGRATE_MAX_RETRIES: "12"
      MIGRATE_RETRY_INTERVAL: "5"
      MIGRATE_BASELINE_VERSION: ${MIGRATE_BASELINE_VERSION:-}
      ATLAS_ENV: ${ATLAS_ENV:-kubernetes}
      ATLAS_REVISIONS_SCHEMA: "public"
    volumes:
      - ./migrations-atlas/migrations:/migrations:ro
    depends_on:
      db:
        condition: service_healthy
    networks:
      - alt-network

  recap-db-migrator:
    build:
      context: ./recap-migration-atlas
      dockerfile: docker/Dockerfile
    container_name: recap_db_migrator
    command: ["apply"]
    environment:
      DATABASE_URL: "postgres://${RECAP_DB_USER}:${RECAP_DB_PASSWORD}@recap-db:${RECAP_DB_PORT}/${RECAP_DB_NAME}?sslmode=disable&search_path=public"
      ATLAS_ENV: ${ATLAS_ENV:-kubernetes}
      ATLAS_REVISIONS_SCHEMA: "public"
      MIGRATE_BASELINE_VERSION: ${RECAP_MIGRATE_BASELINE_VERSION:-}
    volumes:
      - ./recap-migration-atlas/migrations:/migrations:ro
    depends_on:
      recap-db:
        condition: service_healthy
    networks:
      - alt-network
    profiles:
      - recap

  dashboard:
    <<: *shared-env-file
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    profiles:
      - recap
    ports:
      - "8501:8501"
    environment:
      - RECAP_DB_DSN=postgresql://${RECAP_DB_USER}:${RECAP_DB_PASSWORD}@recap-db:5432/${RECAP_DB_NAME}
    depends_on:
      recap-db:
        condition: service_healthy
    networks:
      - alt-network
    restart: unless-stopped
    labels:
      - rask.group=dashboard
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

################### For Rask Log Aggregator ###################
  nginx-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:nginx"
    <<: *rask-forwarder-env
    environment:
      TARGET_SERVICE: "${NGINX_TARGET:-nginx}"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    group_add:
      - "${DOCKER_GROUP_ID:-984}"  # docker group (fallback to 984)
    restart: unless-stopped
    profiles:
      - logging

  alt-backend-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:alt-backend"
    <<: *rask-forwarder-env
    environment:
      TARGET_SERVICE: "${ALT_BACKEND_TARGET:-alt-backend}"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    group_add:
      - "${DOCKER_GROUP_ID:-984}"  # docker group (fallback to 984)
    restart: unless-stopped
    profiles:
      - logging

  tag-generator-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:tag-generator"
    <<: *rask-forwarder-env
    environment:
      TARGET_SERVICE: "tag-generator"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    group_add:
      - "${DOCKER_GROUP_ID:-984}"  # docker group (fallback to 984)
    restart: unless-stopped
    profiles:
      - logging

  pre-processor-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:pre-processor"
    <<: *rask-forwarder-env
    environment:
      TARGET_SERVICE: "pre-processor"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    group_add:
      - "${DOCKER_GROUP_ID:-984}"  # docker group (fallback to 984)
    restart: unless-stopped
    profiles:
      - logging

  search-indexer-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:search-indexer"
    <<: *rask-forwarder-env
    environment:
      TARGET_SERVICE: "search-indexer"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    group_add:
      - "${DOCKER_GROUP_ID:-984}"  # docker group (fallback to 984)
    restart: unless-stopped
    profiles:
      - logging

  news-creator-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:news-creator"
    <<: *rask-forwarder-env
    environment:
      TARGET_SERVICE: "news-creator"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    group_add:
      - "${DOCKER_GROUP_ID:-984}"  # docker group (fallback to 984)
    restart: unless-stopped
    profiles:
      - logging

  meilisearch-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:meilisearch"
    <<: *rask-forwarder-env
    environment:
      TARGET_SERVICE: "meilisearch"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    restart: unless-stopped
    profiles:
      - logging

  db-logs:
    build:
      context: ./rask-log-forwarder/app
      dockerfile: Dockerfile.rask-log-forwarder
    network_mode: "service:db"
    <<: *rask-forwarder-env
    environment:
      TARGET_SERVICE: "db"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    restart: unless-stopped
    profiles:
      - logging

  kratos-migrate:
    image: oryd/kratos:v1.3.0
    command: ["kratos", "migrate", "sql", "-e", "--yes", "--config", "/etc/config/kratos/kratos.yml"]
    environment:
      - KRATOS_DB_USER=${KRATOS_DB_USER:-kratos_user}
      - KRATOS_DB_PASSWORD_FILE=/run/secrets/kratos_db_password
      - KRATOS_DB_HOST=${KRATOS_DB_HOST:-kratos-db}
      - KRATOS_DB_PORT=${KRATOS_DB_PORT:-5432}
      - KRATOS_DB_NAME=${KRATOS_DB_NAME:-kratos}
      - KRATOS_DB_SSLMODE=${KRATOS_DB_SSLMODE:-disable}
    secrets:
      - kratos_db_password
    volumes:
      - ./kratos:/etc/config/kratos:ro
      - ./kratos/entrypoint.sh:/entrypoint.sh:ro
    entrypoint: ["/entrypoint.sh"]
    depends_on:
      kratos-db:
        condition: service_healthy
    restart: "no"
    networks:
      - alt-network

  kratos:
    image: oryd/kratos:v1.3.0
    command: ["kratos", "serve", "all", "--config", "/etc/config/kratos/kratos.yml"]
    ports:
      - "4433:4433"  # public
      - "4434:4434"  # admin
    environment:
      - KRATOS_DB_USER=${KRATOS_DB_USER:-kratos_user}
      - KRATOS_DB_PASSWORD_FILE=/run/secrets/kratos_db_password
      - KRATOS_DB_HOST=${KRATOS_DB_HOST:-kratos-db}
      - KRATOS_DB_PORT=${KRATOS_DB_PORT:-5432}
      - KRATOS_DB_NAME=${KRATOS_DB_NAME:-kratos}
      - KRATOS_DB_SSLMODE=${KRATOS_DB_SSLMODE:-disable}
      - KRATOS_PUBLIC_URL=${KRATOS_PUBLIC_URL:-http://localhost/ory}
      - KRATOS_ADMIN_URL=${KRATOS_ADMIN_URL:-http://kratos-admin:4434/}
      - KRATOS_CORS_ALLOWED_ORIGIN_1=${KRATOS_CORS_ALLOWED_ORIGIN_1:-http://localhost:4173}
      - KRATOS_CORS_ALLOWED_ORIGIN_2=${KRATOS_CORS_ALLOWED_ORIGIN_2:-http://localhost}
      - KRATOS_DEFAULT_BROWSER_RETURN_URL=${KRATOS_DEFAULT_BROWSER_RETURN_URL:-http://localhost:4173/sv/}
      - KRATOS_ALLOWED_RETURN_URL_1=${KRATOS_ALLOWED_RETURN_URL_1:-http://localhost:4173/sv/}
      - KRATOS_ALLOWED_RETURN_URL_2=${KRATOS_ALLOWED_RETURN_URL_2:-http://localhost:4173/sv/home}
      - KRATOS_ALLOWED_RETURN_URL_3=${KRATOS_ALLOWED_RETURN_URL_3:-http://localhost:4173/sv/auth/login}
      - KRATOS_LOGIN_UI_URL=${KRATOS_LOGIN_UI_URL:-http://localhost:4173/sv/auth/login}
      - KRATOS_REGISTRATION_UI_URL=${KRATOS_REGISTRATION_UI_URL:-http://localhost:4173/sv/register}
      - KRATOS_ERROR_UI_URL=${KRATOS_ERROR_UI_URL:-http://localhost:4173/sv/error}
      - KRATOS_SETTINGS_UI_URL=${KRATOS_SETTINGS_UI_URL:-http://localhost:4173/sv/settings}
      - KRATOS_RECOVERY_UI_URL=${KRATOS_RECOVERY_UI_URL:-http://localhost:4173/sv/recovery}
      - KRATOS_VERIFICATION_UI_URL=${KRATOS_VERIFICATION_UI_URL:-http://localhost:4173/sv/verification}
      - KRATOS_COOKIE_SECRET_FILE=/run/secrets/kratos_cookie_secret
      - KRATOS_CIPHER_SECRET_FILE=/run/secrets/kratos_cipher_secret
    secrets:
      - kratos_db_password
      - kratos_cookie_secret
      - kratos_cipher_secret
    volumes:
      - ./kratos:/etc/config/kratos:ro
      - ./kratos/entrypoint.sh:/entrypoint.sh:ro
    entrypoint: ["/entrypoint.sh"]
    depends_on:
      kratos-db:
        condition: service_healthy
      kratos-migrate:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "wget --spider -q http://127.0.0.1:4434/admin/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - alt-network

  auth-hub:
    build:
      context: ./auth-hub
      dockerfile: Dockerfile
    environment:
      - KRATOS_URL=http://kratos:4433
      - PORT=8888
      - CACHE_TTL=5m
      - CSRF_SECRET_FILE=/run/secrets/csrf_secret
      - AUTH_SHARED_SECRET_FILE=/run/secrets/auth_shared_secret
      - BACKEND_TOKEN_SECRET_FILE=/run/secrets/backend_token_secret
      - BACKEND_TOKEN_ISSUER=auth-hub
      - BACKEND_TOKEN_AUDIENCE=alt-backend
      - BACKEND_TOKEN_TTL=5m
    secrets:
      - csrf_secret
      - auth_shared_secret
      - backend_token_secret
    depends_on:
      kratos:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - alt-network
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M
    labels:
      - rask.group=alt-auth
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# Classification/Embedding デバイス分離設定 & CUDA Fork Error 対策

## ADR's STATUS

**承認済み（Accepted）** - 2026年1月3日

## CONTEXT

### 問題1: GPU OOM

7days Recapの日次ジョブでクラスタリング処理がタイムアウト（300秒）する問題が発生。
GPUを使用して高速化を試みたが、Classification（Learning Machine）とEmbedding（Clustering）
の両モデルが同一の`device`設定を共有しているため、同時にGPUにロードしようとして
OOM（Out of Memory）エラーが発生した。

### 問題2: CUDA Fork Error

デバイス分離設定後、以下のエラーが発生：

```
RuntimeError: Cannot re-initialize CUDA in forked subprocess.
To use CUDA with multiprocessing, you must use the 'spawn' start method
```

[PyTorch公式ドキュメント](https://pytorch.org/docs/stable/notes/multiprocessing.html)によると：
> "CUDA runtime does not support the fork start method"

GunicornはforkでワーカーをSpawnするため、ワーカー内でCUDAを使用できない。

### 環境

- RTX 4060 8GB
- Ollama使用中: ~4.7GB
- 空きVRAM: ~2.7GB

### 使用モデル

| モデル | 用途 | VRAMサイズ |
|--------|------|-----------|
| multilingual-e5-large | Embedding (クラスタリング) | ~1.3GB |
| DistilBERT x2 | Classification (JA/EN) | ~550MB |

両モデル合計 ~1.85GB は空きVRAM ~2.7GB に収まるが、
Ollamaとの同時使用時にOOMが発生。

## DECISION

`classification_device` 設定を新設し、ClassificationとEmbeddingで
異なるデバイスを指定可能にする。

### 変更内容

1. **config.py**: `classification_device` フィールド追加
   - デフォルト: `None`（`device` の値を継承）
   - 環境変数: `RECAP_SUBWORKER_CLASSIFICATION_DEVICE`, `RECAP_CLASSIFICATION_DEVICE`

2. **classification_worker.py**: 分類モデルで `classification_device` を使用

3. **compose/recap.yaml**: デフォルト設定を変更
   - `RECAP_SUBWORKER_DEVICE=cuda` (Embedding用)
   - `RECAP_SUBWORKER_CLASSIFICATION_DEVICE=cpu` (Classification用)
   - GPU予約設定を追加

### CUDA Fork Error 対策

PyTorchのCUDAランタイムはforkをサポートしないため、以下の対策を実施：

1. **遅延インポート（Lazy Import）**
   - マスタープロセスでtorchがインポートされるとfork後にCUDAが使用不可になる
   - `classification_runner.py`: `classification_worker`モジュールを使用時にインポート
   - `classification_worker.py`: `LearningMachineStudentClassifier`を`initialize()`内でインポート

2. **Gunicorn → Uvicorn 切り替え**
   - Gunicornはforkでワーカーを生成するためCUDAと非互換
   - Uvicornシングルプロセスモードでforkを回避
   - Classificationは`spawn`コンテキストの専用プロセスプールで実行

```python
# classification_runner.py - 遅延インポート例
def _ensure_pool(self) -> multiprocessing.Pool:
    from . import classification_worker  # Lazy import
    ctx = multiprocessing.get_context("spawn")  # spawn使用
    self._pool = ctx.Pool(...)
```

### 設定例

```bash
# 分離設定（推奨）
export RECAP_SUBWORKER_DEVICE=cuda                    # Embedding用GPU
export RECAP_SUBWORKER_CLASSIFICATION_DEVICE=cpu       # Classification用CPU

# 後方互換（単一設定）
export RECAP_SUBWORKER_DEVICE=cpu                      # 両方CPU
```

## RESULTS

### パフォーマンス改善（期待値）

| 処理 | CPU | GPU | 改善率 |
|------|-----|-----|--------|
| Embedding (1000docs) | ~60秒 | ~5秒 | 12x |
| Clustering全体 | ~300秒 (タイムアウト) | ~30秒 | 10x |

### リソース使用

| コンポーネント | メモリ使用量 |
|----------------|-------------|
| multilingual-e5-large (GPU) | ~1.3GB VRAM |
| DistilBERT x2 (CPU) | ~550MB RAM |
| 合計GPU使用 | ~1.3GB (空き2.7GB内) |

### 後方互換性

- `classification_device` 未設定時は `device` の値を継承
- 既存の設定（`RECAP_SUBWORKER_DEVICE=cpu` のみ）は変更不要で動作

## 変更ファイル一覧

| ファイル | 変更内容 |
|----------|----------|
| `recap-subworker/recap_subworker/infra/config.py` | `classification_device` フィールド追加 |
| `recap-subworker/recap_subworker/services/classification_runner.py` | 遅延インポート追加 |
| `recap-subworker/recap_subworker/services/classification_worker.py` | 遅延インポート追加、`classification_device`使用 |
| `recap-subworker/Dockerfile.recap-subworker` | Gunicorn → Uvicorn 切り替え |
| `compose/recap.yaml` | 環境変数追加、GPU予約設定 |

## RELATED

- 関連Issue: 7days Recap タイムアウト問題
- 関連ADR: ADR-047 MLモデルアーティファクトマウント問題

## 参考文献

- [PyTorch Multiprocessing Best Practices](https://pytorch.org/docs/stable/notes/multiprocessing.html) - CUDA fork非対応の公式ドキュメント
- [PyTorch CUDA semantics](https://pytorch.org/docs/stable/notes/cuda.html)
- [Gunicorn CUDA Issue #3176](https://github.com/benoitc/gunicorn/issues/3176)

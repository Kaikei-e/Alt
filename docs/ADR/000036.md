# RAG Orchestrator パフォーマンス最適化

## ステータス

**採択・実装完了（Accepted & Implemented）** - 2025年12月31日

## コンテキスト

### 背景

RAG (Retrieval-Augmented Generation) パイプラインにおいて、Context Retrieval処理に約12秒を要していた。内訳は以下の通り：

| 処理 | 所要時間 | ボトルネック |
|------|----------|-------------|
| Query Expansion | 4-6秒 | 大型LLMでの推論 |
| Vector Search | 5-10秒 | 複合JOINによるインデックス未使用 |
| Embedding | ~160ms | - |

### 課題

1. **Query Expansion**: 大型モデル（20Bパラメータ）をiGPU上で実行しており、軽量タスクに対してオーバースペック
2. **Vector Search**: 3テーブルJOIN + WHERE条件により、HNSWインデックスが効率的に使用されていない
3. **Sequential Execution**: 複数のクエリベクトルに対する検索が順次実行

## 意思決定

### 決定1: Query Expansionの分離とGPUオフロード

Query Expansionを専用の軽量LLMサービスへ委譲：

```
Before:
  rag-orchestrator → iGPU (20B model) → 4-6秒

After:
  rag-orchestrator → news-creator (4B model) → 1-2秒
```

**設計判断:**
- 新規エンドポイント `/api/v1/expand-query` を追加
- 日本語1 + 英語3 = 4クエリ変種を生成
- フォールバック機構により、サービス障害時は従来のLLM展開にフォールバック

**インターフェース:**
```go
type QueryExpander interface {
    ExpandQuery(ctx context.Context, query string, japaneseCount, englishCount int) ([]string, error)
}
```

### 決定2: Two-Stage Vector Search

HNSWインデックスを確実に活用するため、検索を2段階に分離：

```sql
-- Stage 1: Pure vector search (HNSW optimized)
SELECT c.id, (c.embedding <=> $1) as distance
FROM rag_chunks c
ORDER BY distance ASC LIMIT 150;

-- Stage 2: Metadata enrichment with filtering
SELECT c.*, d.article_id, v.title, v.url
FROM rag_chunks c
JOIN rag_document_versions v ON c.version_id = v.id
JOIN rag_documents d ON v.document_id = d.id
WHERE c.id = ANY($1) AND d.current_version_id = v.id;
```

**設計判断:**
- Stage 1でHNSWインデックスを最大限活用（フィルタなし）
- Stage 2のオーバーフェッチを考慮し、`limit * 3` の候補を取得
- 最終的なスコア順ソートをアプリケーション層で実行

**検討した代替案:**

| パターン | メリット | デメリット |
|----------|----------|------------|
| 単一クエリ + Partial Index | シンプル | current_version条件のインデックス効率が不確定 |
| Materialized View | クエリ簡素化 | リフレッシュのオーバーヘッド |
| **Two-Stage（採用）** | HNSW確実活用 | アプリケーション側でソート必要 |

### 決定3: Parallel Vector Search

複数クエリベクトルの検索をgoroutineで並列実行：

```go
resultsChan := make(chan searchResult, len(embeddings))
var wg sync.WaitGroup

for i, queryVector := range embeddings {
    wg.Add(1)
    go func(idx int, qv []float32) {
        defer wg.Done()
        results, err := chunkRepo.Search(ctx, qv, candidateIDs, limit)
        resultsChan <- searchResult{index: idx, results: results, err: err}
    }(i, queryVector)
}
```

**設計判断:**
- Original query + Expanded queries (4-5本) を同時実行
- データベースコネクションプールは既存設定で十分
- エラーは最初の1件のみ返却（fail-fast）

### 決定4: 補助インデックスの追加

Stage 2のJOINを高速化するためのインデックス：

```sql
CREATE INDEX idx_rag_documents_current_version ON rag_documents(current_version_id);
CREATE INDEX idx_rag_chunks_version_id ON rag_chunks(version_id);
CREATE INDEX idx_rag_document_versions_doc_id ON rag_document_versions(document_id);
```

## 結果・効果

### 実測パフォーマンス

実装後のベンチマーク結果（クエリ: `AI技術のトレンド`、5回実行の平均）:

| 処理 | Before | After | 改善率 |
|------|--------|-------|--------|
| Query Expansion | 4-6秒 | **~1秒** | 80% |
| Embedding | ~160ms | **~155ms** | - |
| Vector Search (9並列) | 5-10秒 | **10-32ms** | 99% |
| **Total Retrieval** | **~12秒** | **~1.4秒** | **88%** |

**ベンチマーク詳細:**

```
Run 1: 1.46s
Run 2: 1.36s
Run 3: 1.37s
Run 4: 1.53s
Run 5: 1.37s
─────────────
平均:  1.42s
```

**処理内訳ログ（実測）:**

```json
{"msg":"query_expansion_completed","elapsed_ms":1079}
{"msg":"queries_encoded","query_count":9}
{"msg":"parallel_vector_search_completed","query_count":9,"duration_ms":32}
{"msg":"retrieval_completed","contexts_returned":10,"duration_ms":1303}
```

### PROS

1. **GPUリソースの効率化**
   - 軽量タスクを専用GPU（高スループット）へ分離
   - 大型モデルは複雑な推論タスクに専念

2. **スケーラビリティ**
   - Query Expansionサービスは水平スケール可能
   - Two-Stageパターンはデータ量増加に対して安定

3. **フォールバック機構**
   - 新サービス障害時も従来処理で継続可能
   - 段階的ロールアウトが可能

### CONS / TRADEOFF

1. **サービス間依存の増加**
   - rag-orchestrator → news-creator の依存追加
   - ネットワークレイテンシの追加（~10ms）

2. **メモリ使用量の増加**
   - Two-Stage検索でのオーバーフェッチ
   - 並列検索での一時的なメモリ消費

3. **複雑性の増加**
   - 2段階クエリのデバッグが若干複雑に
   - goroutineエラーハンドリングの考慮

## 付録

### アーキテクチャ図

```
┌─────────────────────────────────────────────────────────────┐
│                    rag-orchestrator                          │
├─────────────────────────────────────────────────────────────┤
│  1. Query Expansion → news-creator (GPU, 4B) ──── ~1秒      │
│  2. Embedding       → embedder (iGPU)        ──── ~155ms    │
│  3. Vector Search   → PostgreSQL/pgvector    ──── ~30ms     │
│     └─ Stage 1: HNSW pure search (9並列)                    │
│     └─ Stage 2: Metadata JOIN                               │
│  4. LLM Answer      → augur (iGPU, 20B)                     │
├─────────────────────────────────────────────────────────────┤
│  Total Retrieval (1-3): ~1.4秒 (Before: ~12秒, 88%改善)     │
└─────────────────────────────────────────────────────────────┘
```

### 変更ファイル一覧

| カテゴリ | ファイル |
|---------|---------|
| news-creator | `usecase/expand_query_usecase.py`, `handler/expand_query_handler.py`, `domain/models.py` |
| rag-orchestrator Adapter | `adapter/rag_augur/query_expander_client.go` |
| rag-orchestrator Domain | `domain/llm_client.go` (QueryExpander interface) |
| rag-orchestrator Usecase | `usecase/retrieve_context_usecase.go` |
| rag-orchestrator Repository | `adapter/repository/rag_chunk_repo.go` |
| Migration | `migrations/20251231_optimize_vector_search.sql` |
| Config | `compose.yaml`, `.env.template` |

### 環境変数

```bash
# Query Expansion Service
QUERY_EXPANSION_URL=http://news-creator:11434
QUERY_EXPANSION_TIMEOUT=30
```

### 関連ADR

- ADR-000025: RAG Pipeline初期設計
- ADR-000028: pgvector導入とHNSWインデックス

# バックアップシステム堅牢化

## ADR's STATUS

Accepted (実装完了)

## CONTEXT

### 問題点

Alt platform のバックアップシステムには 3-2-1 戦略・Restic 暗号化・systemd スケジューリング・Prometheus 監視・Grafana アラート・altctl CLI など基盤が整っていたが、以下の問題を発見:

| # | 分類 | 問題 |
|---|------|------|
| 1 | バグ | `backup-all.sh` の Redis Streams volume パスに改行が混入し、バックアップ対象から漏れる |
| 2 | バグ | ClickHouse バックアップで存在しないユーザー名をハードコード |
| 3 | バグ | altctl volume registry に `redis-streams-data`, `prometheus_data`, `grafana_data` が未登録 |
| 4 | 構造的問題 | Docker コンテナが idle 状態 (`tail -f /dev/null`) でスケジュール未設定 |
| 5 | 構造的問題 | altctl が PostgreSQL に対して tar バックアップを使用 (pg_dump 未使用) |
| 6 | 構造的問題 | Meilisearch スナップショット API 呼び出し後に完了を待機しない |
| 7 | 構造的問題 | 復元検証の自動化なし |
| 8 | 構造的問題 | ログローテーションなし |
| 9 | 機能不足 | バックアップ状態を一覧表示する CLI コマンドなし |

### 方針

3-2-1-1-0 ルール (自動復元検証によるゼロエラー) に基づき、7 つの Work Package で改善。コンテナネイティブスケジューリング (supercronic) を導入し、systemd 依存を軽減。

## DECISION MAKING

### WP1: バグ修正

#### 1A: Redis Streams volume パスの改行修正

`backup-all.sh` の volumes 配列で `"/data/redis-streams-\n        data"` と改行が混入していたため、Restic バックアップ対象から漏れていた。1 行に修正。

#### 1B: ClickHouse ユーザー名の環境変数化

ハードコードされた `rask_db_user` を `${CLICKHOUSE_USER:-rask_user}` に変更し、環境変数でオーバーライド可能に。

#### 1C: 欠落 volume の追加

altctl の `VolumeRegistry` に 3 件追加:

| Volume | Service | 用途 |
|--------|---------|------|
| `redis-streams-data` | redis-streams | メッセージキューデータ |
| `prometheus_data` | prometheus | 監視データ |
| `grafana_data` | grafana | ダッシュボード設定 |

### WP2: Meilisearch スナップショット待機

スナップショット API (`POST /snapshots`) 呼び出し後、`GET /tasks/{taskUid}` をポーリングして完了を待機:

- `succeeded` → 成功ログ出力して続行
- `failed` → エラーログ出力
- タイムアウト 120 秒 (ポーリング間隔 5 秒) → 警告ログ

### WP3: altctl pg_dump 対応 + 事前整合性チェック

#### 3A: PostgreSQL バックアップドライバー

`PostgresBackuper` を新設し、`VolumeRegistry` の 4 つの PostgreSQL volume を `BackupTypeTar` から `BackupTypePostgreSQL` に変更:

| Volume | Service | DBName | DBUser |
|--------|---------|--------|--------|
| `db_data_17` | db | alt | alt_db_user |
| `kratos_db_data` | kratos-db | kratos | kratos_user |
| `recap_db_data` | recap-db | recap | recap_user |
| `rag_db_data` | rag-db | rag_db | rag_user |

バックアップ: `docker exec <container> pg_dump -U <user> --format=custom --compress=6 <dbname>`
リストア: `docker exec -i <container> pg_restore -U <user> -d <dbname> --clean --if-exists`

`Migrator.backupVolume()` と `Migrator.restoreVolume()` に `BackupType` ベースのディスパッチを追加。リストア時はファイル拡張子 (`.tar.gz` / `.dump`) で判定し、旧形式バックアップとの後方互換性を維持。

#### 3B: 事前 CHECKPOINT

`backup_volumes()` 実行前に全 PostgreSQL コンテナで `CHECKPOINT` を発行し、volume バックアップ時のデータ整合性を向上。

### WP4: コンテナネイティブスケジューリング

#### 4A: supercronic 導入

restic-backup コンテナ起動時に supercronic v0.2.33 をダウンロードし、crontab ベースのスケジューリングを実行。`tail -f /dev/null` (idle) からの脱却。

```
0 * * * *   /scripts/backup-all.sh --pg-only          # 毎時 PG バックアップ
0 3 * * *   /scripts/backup-all.sh --prune --verify    # 毎日 03:00 フルバックアップ
0 5 * * *   /scripts/sync-offsite.sh --prune-remote    # 毎日 05:00 オフサイト同期
30 * * * *  /scripts/backup-metrics.sh                 # 30 分ごとメトリクス更新
0 6 * * 0   /scripts/restore-verify.sh                 # 毎週日曜 06:00 復元検証
0 4 * * *   find /backups/logs/ ... -mtime +30 -delete # 毎日 04:00 ログローテーション
```

#### 4B: postgres-backup サイドカー削除

`backup-all.sh` が `docker exec` 経由で pg_dump を実行するため、独立した postgres-backup コンテナは不要。compose/backup.yaml から削除し、スタックレジストリも更新。

#### 4C: systemd EnvironmentFile 方式

3 つの systemd service ファイルで Environment ディレクティブを `EnvironmentFile=-/etc/alt-backup.env` に変更。共有環境設定ファイル `alt-backup.env` を新設。

### WP5: ログローテーション

`backup-all.sh` の `main()` 末尾で 30 日超のログファイルを自動削除。WP4 の crontab にも毎日 04:00 のローテーションジョブを定義。

### WP6: `altctl migrate status` コマンド

バックアップ状態を集約表示する CLI コマンドを新設:

- 最新バックアップのタイムスタンプ・経過時間
- 期待 volume 数 vs 実際の volume 数
- 欠落 volume の一覧
- 合計サイズ
- チェックサム検証状態
- RPO しきい値 (25 時間) に基づく健全性判定

健全性レベル:

| Level | 条件 |
|-------|------|
| GOOD | 新しいバックアップ + 全 volume + チェックサム OK |
| WARNING | 25h 超過、volume 欠落、またはチェックサム不一致 |
| CRITICAL | バックアップなし、または 50h 超過 |

### WP7: 自動リストア検証

`restore-verify.sh` (~310 行) を新設:

1. 最新 Restic スナップショットを一時ディレクトリにリストア
2. PostgreSQL dump ファイルを一時コンテナで `pg_restore` 検証
3. リストアされた volume データの整合性チェック (ファイル数確認)
4. Prometheus メトリクス出力 (`backup_restore_verify_last_timestamp`, `backup_restore_verify_success`, `backup_restore_verify_duration_seconds`)
5. 全一時リソース (コンテナ・ボリューム・ディレクトリ) のクリーンアップ
6. healthchecks.io に結果送信

Grafana アラート 2 件追加:

| UID | 条件 | 重要度 |
|-----|------|--------|
| `backup-restore-verify-stale` | 8 日間未実行 | warning |
| `backup-restore-verify-failed` | 最新検証が失敗 | critical |

## RESULTS, EFFECTS

### 変更ファイル一覧

| 操作 | ファイル | WP | 変更内容 |
|------|---------|-----|---------|
| 修正 | `scripts/backup/backup-all.sh` | 1,2,3,5 | バグ修正 3 件 + Meili 待機 + CHECKPOINT + ログクリーンアップ |
| 修正 | `altctl/internal/migrate/registry.go` | 1,3 | volume 3 件追加 + PG 4 件の型変更 |
| 修正 | `altctl/internal/migrate/registry_test.go` | 1,3 | カウント・型テスト更新 |
| 修正 | `altctl/internal/migrate/backup.go` | 3 | BackupType ディスパッチ + pgBackup フィールド |
| 修正 | `altctl/internal/migrate/restore.go` | 3 | リストアディスパッチ + 後方互換 |
| 修正 | `compose/backup.yaml` | 4 | supercronic スケジューリング、postgres-backup 削除 |
| 修正 | `scripts/backup/systemd/*.service` (3 files) | 4 | EnvironmentFile 方式 |
| 修正 | `altctl/internal/stack/registry.go` | 4 | backup スタックから postgres-backup 削除 |
| 修正 | `altctl/internal/output/hints.go` | 6 | migrate status ヒント追加 |
| 修正 | `observability/alerts/backup-rules.yaml` | 7 | 復元検証アラート 2 件追加 |
| 修正 | `scripts/backup/backup-metrics.sh` | 7 | 復元検証メトリクス収集 |
| 修正 | `docs/runbooks/backup-restore.md` | 7 | 自動リストア検証セクション追加 |
| 修正 | `scripts/backup/README.md` | 7 | 新規スクリプトのドキュメント |
| 新規 | `altctl/internal/migrate/postgres.go` | 3 | pg_dump/pg_restore ドライバー |
| 新規 | `altctl/internal/migrate/postgres_test.go` | 3 | TDD テスト (8 件) |
| 新規 | `altctl/internal/migrate/status.go` | 6 | バックアップ状態集約 |
| 新規 | `altctl/internal/migrate/status_test.go` | 6 | TDD テスト (5 件) |
| 新規 | `altctl/cmd/migrate_status.go` | 6 | CLI コマンド定義 |
| 新規 | `scripts/backup/crontab` | 4 | supercronic スケジュール定義 |
| 新規 | `scripts/backup/alt-backup.env` | 4 | 共有環境設定ファイル |
| 新規 | `scripts/backup/restore-verify.sh` | 7 | 自動リストア検証スクリプト |

### テスト結果

| パッケージ | 結果 |
|-----------|------|
| `cmd` | PASS |
| `internal/compose` | PASS |
| `internal/migrate` | PASS (30 テスト) |
| `internal/output` | PASS |
| `internal/stack` | PASS |

新規テスト: 13 件 (postgres: 8, status: 5)

### 動作確認

- `go build ./...`: 成功
- `go test ./... -count=1`: 全パッケージ通過
- `bash -n` (構文チェック): backup-all.sh, restore-verify.sh, backup-metrics.sh 全 OK
- Docker コンテナ起動:
  - `docker compose --profile backup up -d restic-backup` → 成功
  - `docker inspect alt-backup --format '{{.State.Health.Status}}'` → `healthy`
  - `docker logs alt-backup` → supercronic v0.2.33 起動、crontab 読み込み成功

### PROS

1. **データ整合性**: pg_dump による論理バックアップで、tar コピーよりも信頼性の高い PostgreSQL バックアップ
2. **自動スケジューリング**: supercronic によるコンテナネイティブスケジューリングで、systemd 不要のコンテナ内完結型運用
3. **復元検証**: 3-2-1-1-0 ルールの「0 エラー」を自動検証で担保
4. **可観測性強化**: 復元検証メトリクス + Grafana アラート 2 件で検証失敗を即時検知
5. **バグ修正**: Redis Streams、ClickHouse、volume 欠落の 3 件のサイレント障害を解消
6. **運用効率**: `altctl migrate status` で健全性を一目で確認。ログ自動ローテーション
7. **後方互換**: 旧 tar 形式のバックアップもリストア可能

### CONS, TRADEOFF

1. **コンテナ起動時間の増加**: supercronic をコンテナ起動時にダウンロードするため、初回起動に ~20 秒の遅延。Dockerfile でベイク可能だが、restic 公式イメージの活用を優先
2. **pg_dump はコンテナ稼働必須**: tar バックアップは停止中の volume でも可能だが、pg_dump はデータベースコンテナの稼働が必要。`--force` フラグとの組み合わせで対応
3. **復元検証のリソース消費**: 週次で一時 PostgreSQL コンテナを起動するため、一時的にメモリ・ディスクを消費。クリーンアップは自動化済み

## APPENDIX

### 依存関係グラフ

```
WP1 (バグ修正) ──────────────┐
WP5 (ログローテーション) ────┤
WP2 (Meilisearch 待機) ──────┼──→ WP4 (コンテナスケジューリング)
WP6 (status コマンド) ────────┤            │
WP3 (pg_dump 対応) ───────────┘            │
                                           ▼
                                WP7 (自動リストア検証)
```

### supercronic スケジュール

| スケジュール | コマンド | 用途 |
|-------------|---------|------|
| `0 * * * *` | `backup-all.sh --pg-only` | 毎時 PG バックアップ |
| `0 3 * * *` | `backup-all.sh --prune --verify` | 日次フルバックアップ |
| `0 5 * * *` | `sync-offsite.sh --prune-remote` | 日次オフサイト同期 |
| `30 * * * *` | `backup-metrics.sh` | 30 分ごとメトリクス |
| `0 6 * * 0` | `restore-verify.sh` | 週次復元検証 |
| `0 4 * * *` | `find ... -mtime +30 -delete` | 日次ログローテーション |

### 関連 ADR

- ADR-000188: search-indexer Clean Architecture リファクタリング (テスト駆動開発パターンの参考)

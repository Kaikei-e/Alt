# ADR 101: LLM品質評価におけるコンテキストウィンドウ超過の防止

## ステータス

採択（Accepted）

## コンテキスト

### 背景

pre-processorサービスの品質評価機能（Quality Checker）において、LLMへ送信するプロンプトがモデルのコンテキストウィンドウを超過する問題が発生していた。

### 課題

| 課題 | 詳細 |
|------|------|
| プロンプト切り捨て | モデルのコンテキスト上限を超えるプロンプトが自動的に切り捨てられる |
| 不正な出力 | 切り捨てにより評価指示が失われ、モデルが意味不明な繰り返しパターンを出力 |
| 誤判定 | パース失敗によりフォールバックスコア（最低値）が適用され、正常なサマリーが削除される |

### 観測されたエラーパターン

```
level=WARN msg="truncating input prompt" limit=16384 prompt=21557
```

モデルが出力した不正なレスポンス例:
- `length(&s_length(&s_length(&s...`（繰り返しパターン）
- `/*#text x=")}#text x=")}...`（XMLのような繰り返し）
- `...`（ドットの連続）

### 根本原因

1. 品質評価用モデルのコンテキストウィンドウ: 16,384トークン
2. 実際の入力プロンプト: 21,000〜24,000トークン（記事 + サマリー + 評価テンプレート）
3. 要約処理（Summarizer）には既にコンテンツ長チェックが存在するが、品質評価（Quality Checker）には未実装

## 決定

Summarizerと同様のパターンを適用し、Quality Checkerにもコンテンツ長チェックを追加する。

### 設計方針

| 方針 | 理由 |
|------|------|
| 事前チェック | LLMへの無駄なリクエストを防止 |
| エラーではなくスキップ | サマリーは保持し、品質評価のみをスキップ |
| 既存パターンの踏襲 | Summarizerと一貫した実装 |

### 上限値の算出

```
コンテキストウィンドウ: 16,384トークン
プロンプトテンプレート: 約400トークン
出力予約: 60トークン
利用可能: 約15,900トークン

日本語換算（4文字/トークン）: 約64,000文字
安全マージン込み: 50,000文字
```

## 実装

### 変更ファイル

| ファイル | 変更内容 |
|---------|---------|
| `pre-processor/app/quality-checker/quality_judger.go` | 定数追加、コンテンツ長チェック追加 |
| `pre-processor/app/quality-checker/quality_judger_test.go` | テストケース追加 |

### コード変更

#### 定数定義

```go
var (
    lowScoreThreshold = 7
    // Quality Checker用: 16kコンテキストモデルで安定動作する上限
    // 記事 + サマリー + プロンプトテンプレート(~1500文字) < 16k トークン
    // 日本語は約4文字/トークンなので、記事+サマリーは約50,000文字まで
    maxQualityCheckContentLength = 50_000
)
```

#### JudgeArticleQuality関数

```go
func JudgeArticleQuality(ctx context.Context, dbPool *pgxpool.Pool,
    articleWithSummary *driver.ArticleWithSummary) error {

    if articleWithSummary == nil || articleWithSummary.ArticleID == "" {
        return errors.New("article with summary is invalid")
    }

    // コンテンツ長チェック: 長すぎる場合はスキップ（サマリーは保持）
    totalContentLength := len(articleWithSummary.Content) +
        len(articleWithSummary.SummaryJapanese)
    if totalContentLength > maxQualityCheckContentLength {
        logger.Logger.Info("Skipping quality check: content too long",
            "articleID", articleWithSummary.ArticleID,
            "content_length", len(articleWithSummary.Content),
            "summary_length", len(articleWithSummary.SummaryJapanese),
            "total_length", totalContentLength,
            "max_allowed", maxQualityCheckContentLength)
        return nil
    }

    // 既存の品質評価処理...
}
```

### テストケース

| テスト名 | 検証内容 |
|---------|---------|
| `TestJudgeArticleQualityContentTooLong` | 上限超過時のスキップ動作 |
| `TestJudgeArticleQualityContentWithinLimit` | 上限内での正常処理 |
| `TestJudgeArticleQualityContentBoundary` | 境界値（上限ちょうど、1バイト超過） |
| `TestMaxQualityCheckContentLengthConstant` | 定数値の検証 |

## 結果

### 修正後の動作

| 状態 | 動作 |
|------|------|
| コンテンツ長 ≤ 50,000文字 | 通常通り品質評価を実行 |
| コンテンツ長 > 50,000文字 | 品質評価をスキップ、サマリーは保持 |

### 期待される効果

| 効果 | 詳細 |
|------|------|
| エラー削減 | `truncating input prompt` 警告の解消 |
| データ保護 | 誤判定によるサマリー削除の防止 |
| リソース効率 | 無駄なLLMリクエストの削減 |

### トレードオフ

| PROS | CONS |
|------|------|
| シンプルな実装 | 長いコンテンツの品質評価がスキップされる |
| 既存パターンとの一貫性 | 将来的にモデルを変更した場合は上限値の調整が必要 |
| TDDによる堅牢性 | - |

## 代替案

| 案 | 不採用理由 |
|----|-----------|
| より大きなコンテキストを持つモデルに変更 | GPUメモリ消費が増加、レイテンシ悪化 |
| プロンプトの動的圧縮 | 実装複雑化、評価精度への影響が未知数 |
| コンテンツの分割評価 | 評価の一貫性担保が困難 |

## 実装日

2026-01-15

## 関連

- [Ollama Context Length Best Practices](https://github.com/ollama/ollama/issues/10974)
- [OpenTelemetry Semantic Conventions](https://opentelemetry.io/docs/concepts/semantic-conventions/)

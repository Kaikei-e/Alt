# ML モデルアーティファクトの Docker コンテナへの配布戦略

## ADR's STATUS

**承認済み（Accepted）** - 2026年1月3日

## CONTEXT

### 問題の発生

定期実行される ML 推論ジョブが失敗していた。エラーログには以下のメッセージが記録されていた：

```
RuntimeError: At least one model (JA or EN) must be loaded
Failed to initialize classification worker pool within 300s
```

### 根本原因の分析

調査の結果、以下の状況が判明した：

1. **`.dockerignore` での除外**
   - ADR-046 で導入した Docker ビルド最適化により、ML モデルアーティファクトがイメージから除外されていた
   - 該当ディレクトリ: `learning_machine/artifacts/` (約 5.5GB)

2. **volume マウントの欠落**
   - `.dockerignore` での除外に対応する volume マウント設定が Docker Compose に追加されていなかった
   - コンテナ内にモデルファイルが存在せず、推論サービスが起動時にモデルをロードできなかった

3. **設定の不整合**
   - アプリケーション設定ではモデルパスが指定されていた
   - しかしコンテナ内には該当ディレクトリが存在しなかった

```python
# アプリケーション設定（抜粋）
learning_machine_student_ja_dir: str = "app/learning_machine/artifacts/student/v0_ja"
learning_machine_student_en_dir: str = "app/learning_machine/artifacts/student/v0_en"
```

### 影響

- 定期実行の ML 分類ジョブが全件失敗
- 300秒のタイムアウト後にワーカープール初期化エラー
- リトライ上限に達するまでエラーが繰り返された

## DECISION MAKING

### 検討した選択肢

#### 選択肢 A: Docker イメージにモデルを含める

`.dockerignore` からアーティファクトディレクトリを除外し、イメージに含める。

**PROS:**
- デプロイがシンプル（イメージ単体で完結）
- 環境間でのモデルバージョン一致を保証

**CONS:**
- イメージサイズが 5.5GB 増加
- ビルド時間の増加
- モデル更新時にイメージ再ビルドが必要

#### 選択肢 B: Volume マウントでモデルを配布（採用）

Docker Compose で volume マウントを設定し、ホストのモデルファイルをコンテナにマウントする。

**PROS:**
- イメージサイズを小さく維持
- モデル更新時はコンテナ再起動のみ
- 異なるモデルバージョンのテストが容易

**CONS:**
- ホスト側にモデルファイルの配置が必要
- 環境ごとにモデルファイルの管理が必要

#### 選択肢 C: 外部ストレージからの動的ロード

S3 等のオブジェクトストレージからコンテナ起動時にダウンロード。

**PROS:**
- 中央集権的なモデル管理
- 複数環境での一貫性

**CONS:**
- 起動時間の増加
- ネットワーク依存
- 実装コストが高い

### 決定

**選択肢 B（Volume マウント）を採用**

ADR-046 で確立したビルド最適化を維持しながら、モデル配布の問題を解決する。

### 実装

Docker Compose にモデルアーティファクトの volume マウントを追加：

```yaml
services:
  ml-worker:
    volumes:
      # 既存の設定ファイル
      - ./data/config.json:/app/data/config.json:ro
      # ML モデルアーティファクト（追加）
      - ./learning_machine/artifacts:/app/learning_machine/artifacts:ro
```

### 修正ファイル

| ファイル | 変更内容 |
|----------|----------|
| `compose/services.yaml` | volume マウント設定の追加 |

## RESULTS, EFFECTS

### 検証結果

1. モデルディレクトリがコンテナ内で正しくマウントされることを確認
2. ML 推論サービスが正常に起動し、ヘルスチェックが成功
3. 分類ジョブが正常に実行されることを確認

### PROS

1. **即座の問題解決**
   - コンテナ再起動のみで修正適用
   - イメージ再ビルド不要

2. **ビルド最適化の維持**
   - ADR-046 で達成したビルド時間短縮を維持
   - イメージサイズは小さいまま

3. **柔軟なモデル更新**
   - モデルファイルを更新し、コンテナを再起動するだけで反映
   - 異なるモデルバージョンの A/B テストが容易

### CONS, TRADEOFF

1. **環境構築の追加手順**
   - 新規環境ではモデルファイルの配置が必要
   - ドキュメント化とセットアップスクリプトの整備が必要

2. **モデルバージョン管理**
   - イメージとモデルのバージョン整合性を別途管理する必要
   - Git LFS やモデルレジストリの活用を検討

### 今後の課題

1. **本番環境向けのモデル配布自動化**
   - CI/CD パイプラインでのモデルファイル配布
   - Kubernetes 環境での PersistentVolume 活用

2. **モデルバージョン管理の強化**
   - モデルレジストリの導入検討
   - イメージとモデルのバージョン紐付け

## APPENDIX

### ML モデルの Docker 配布パターン

| パターン | イメージサイズ | 更新容易性 | 実装コスト |
|----------|---------------|-----------|-----------|
| イメージ内蔵 | 大 | 低 | 低 |
| Volume マウント | 小 | 高 | 低 |
| 外部ストレージ | 小 | 高 | 高 |

### ディレクトリ構造

```
project/
├── learning_machine/
│   └── artifacts/
│       ├── student/
│       │   ├── v0_ja/          # 日本語モデル
│       │   └── v0_en/          # 英語モデル
│       └── teacher/
│           └── ...
├── .dockerignore               # artifacts/ を除外
└── compose/
    └── services.yaml           # volume マウント設定
```

### 参考資料

- [Docker Volumes Best Practices](https://docs.docker.com/storage/volumes/)
- [ML Model Serving Patterns](https://ml-ops.org/content/three-levels-of-ml-software)
- ADR-046: Docker ビルドの最適化

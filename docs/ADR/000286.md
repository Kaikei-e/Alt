# Grafana/Prometheus 監視基盤の総点検と致命的バグ修正

## ADR ステータス

承認済み — 2026-02-28

## 背景

Alt プラットフォームの監視基盤（Grafana + Prometheus + ClickHouse）を総点検した結果、以下の致命的な問題群が発見された。

**P0: アラートルール全滅**

| 問題 | 影響範囲 |
|------|---------|
| アラートルール YAML のデータソース UID が不一致（`clickhouse` / `prometheus` → 正しくは `DS_CLICKHOUSE` / `DS_PROMETHEUS`） | 全 Grafana Unified Alerting ルールが実行失敗 |
| `recap-genre-rules.yaml` が Prometheus ネイティブ形式で記述されているが、どこにもロードされていない | recap-genre の 2 ルールが完全に無効 |
| `rask-system-rules.yaml` が存在しないテーブル `logs` を参照（正: `otel_logs`） | rask-system の 3 ルールが静かに失敗 |
| アラートファイルが `observability/alerts/` にあり Grafana のプロビジョニングパスに含まれていない | 全アラートファイルが Grafana に読み込まれない |

**P1: メトリクス収集不足**

Prometheus のスクレイプ対象が 4 個のみ（prometheus, nginx-exporter, cadvisor, alt-backend）で、メトリクスエンドポイントを実装済みの複数のサービスがスクレイプされていなかった。

**P2: Prometheus retention 不足**

SLO ダッシュボードは 30 日ウィンドウを使用するが、Prometheus の retention は 7 日間に設定されていた。

## 意思決定

### Phase 1: P0 致命的問題の修正

#### 1. データソース UID の修正

全アラートルールファイルのデータソース UID を、Grafana プロビジョニングで定義された実際の UID に統一した。

| ファイル | 修正内容 |
|----------|---------|
| `observability/alerts/ai-pipeline-rules.yaml` | `clickhouse` → `DS_CLICKHOUSE`（4 箇所） |
| `observability/alerts/rask-system-rules.yaml` | `clickhouse` → `DS_CLICKHOUSE`（3 箇所） |
| `observability/alerts/backup-rules.yaml` | `prometheus` → `DS_PROMETHEUS`（9 箇所） |

#### 2. rask-system-rules のテーブル名・カラム名修正

ClickHouse のスキーマに合わせて SQL クエリを修正した。

| 旧（存在しない） | 新（`otel_logs` テーブル） |
|-------------------|--------------------------|
| `logs` | `otel_logs` |
| `service_name` | `ServiceName` |
| `level` | `SeverityText` |
| `timestamp` | `Timestamp` |

アノテーションテンプレートとの互換性のため `ServiceName as service_name` のようにエイリアスを付与した。

#### 3. recap-genre-rules の Grafana Unified Alerting 形式への変換

Prometheus ネイティブ形式（`alert:` / `expr:`）から Grafana Unified Alerting 形式（`uid:` / `condition:` / `data:`）に変換した。

| ルール | データソース | PromQL |
|--------|-------------|--------|
| `recap-tag-payload-missing-high` | `DS_PROMETHEUS` | `recap_genre_tag_missing_ratio` > 0.10 |
| `recap-tag-graph-inactive` | `DS_PROMETHEUS` | `increase(recap_genre_graph_hits_total[10m]) == 0 and ...` |

#### 4. アラートファイルのプロビジョニングパス配置

`observability/grafana/provisioning/alerting/` ディレクトリを作成し、アラートルールファイルを配置した。既存の Grafana ボリュームマウント（`provisioning:/etc/grafana/provisioning:ro`）により自動的にロードされる。

### Phase 2: P1 メトリクス収集の拡充

#### 5. Prometheus スクレイプ対象の追加

各サービスのソースコードと Docker Compose 定義からポート番号とメトリクスパスを確認の上、4 サービスを追加した。

| サービス | ポート | パス | 形式 |
|----------|--------|------|------|
| mq-hub | 9500 | `/metrics` | Go promhttp |
| pre-processor | 9201 | `/metrics/prometheus` | カスタム Prometheus |
| recap-worker | 9005 | `/metrics` | Rust prometheus crate |
| recap-subworker | 8002 | `/metrics` | Python FastAPI instrumentator |

**追加しなかったサービス:**

- `rask-log-forwarder`: メトリクスがデフォルト無効、ポート未公開のサイドカーインスタンス
- `sidecar-proxy`: alt-backend 内部のサイドカー、独立した compose サービスではない

#### 6. Prometheus retention の延長

`compose/observability.yaml` にて `--storage.tsdb.retention.time` を `7d` → `31d` に変更し、SLO ダッシュボードの 30 日ウィンドウに対応した。

### 変更対象ファイル一覧

| ファイル | 変更内容 |
|----------|---------|
| `observability/alerts/ai-pipeline-rules.yaml` | datasourceUid 修正 |
| `observability/alerts/rask-system-rules.yaml` | datasourceUid 修正 + テーブル名・カラム名修正 |
| `observability/alerts/backup-rules.yaml` | datasourceUid 修正 |
| `observability/alerts/recap-genre-rules.yaml` | Grafana Unified Alerting 形式に変換 |
| `observability/grafana/provisioning/alerting/*.yaml` | 上記 4 ファイルをプロビジョニングパスに配置 |
| `observability/prometheus/prometheus.yml` | スクレイプ対象 4 サービス追加 |
| `compose/observability.yaml` | Prometheus retention 7d → 31d |

### 検証結果

| 検証項目 | 結果 |
|----------|------|
| Grafana プロビジョニング後のアラートルール数 | 18 ルール全てロード済み |
| データソース UID 検証 | 全ルールが `DS_CLICKHOUSE` / `DS_PROMETHEUS` を正しく使用 |
| Prometheus スクレイプターゲット | 8 ターゲット認識（mq-hub, recap-worker, recap-subworker: UP） |
| Grafana / Prometheus ヘルスチェック | 両方 healthy |

**既知の制限:** `pre-processor` はメトリクスサーバーコード（`metrics/collector.go`）が存在するが、`bootstrap/wire.go` で起動処理が接続されていないため、ターゲットは down のまま。`alt-backend` は `/metrics` エンドポイントが未実装のため同様に down。これらはサービス側の改修が必要。

## 結果・影響

### 利点

- 全 18 のアラートルールが Grafana Unified Alerting で正常に動作するようになった
- Prometheus が 8 サービスからメトリクスを収集できるようになった（従来の 4 から倍増）
- SLO ダッシュボードの 30 日ウィンドウに Prometheus データが対応した
- `http_logs` テーブルは ClickHouse マイグレーション（`002_create_http_logs_table.sql`）で正しく定義されており、Golden Signals / SLO / Nginx Metrics ダッシュボードは正常に動作する

### 欠点・トレードオフ

- Prometheus retention を 31 日に延長したことで、ディスク使用量が増加する。メトリクスのカーディナリティとサンプル数に応じて、ストレージ容量の監視が必要
- `observability/alerts/` と `observability/grafana/provisioning/alerting/` にアラートファイルが重複して存在する。プロビジョニングパスにあるファイルが正とし、`observability/alerts/` は将来的に統合を検討する

## 付録

- Grafana Unified Alerting のプロビジョニングは `provisioning/alerting/` 配下の YAML ファイルを自動ロードする（`apiVersion: 1` 形式）
- Prometheus のスクレイプ対象追加はコンテナ再起動（または `/-/reload` エンドポイント）で反映される
- 今後の改善候補: Recording Rules による SLO 事前集計、バーンレートアラート、サービス個別ダッシュボード、テンプレート変数の導入

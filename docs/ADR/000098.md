# ClickHouse ログ基盤の包括的改善

## ステータス

採択（Accepted）

## コンテキスト

### 背景

ClickHouseに蓄積されたログデータを分析した結果、以下の問題が判明した。

### 問題

| 問題 | 影響 | 重要度 |
|------|------|--------|
| **ノイズ過多** | DB系SQLクエリ断片が全体の74%（約680万件/900万件） | 高 |
| **トレースコンテキスト欠如** | TraceId/SpanIdが全て0、分散トレーシング不可 | 高 |
| **ビジネスコンテキスト不在** | feed_id, article_id, job_idがログに含まれない | 高 |
| **フィールド不均一** | サービスによってfields有無が0%〜100%とバラバラ | 中 |
| **ANSIエスケープ混入** | Meilisearchログに制御文字が残存 | 低 |

### サービス別ログ品質

| サービス | 件数 | fields有り | 品質評価 |
|----------|------|-----------|----------|
| alt-backend | 310K | 99.9% | 良好 |
| pre-processor | 245K | 99.9% | 良好 |
| recap-worker | 3.5K | 100% | 良好 |
| nginx | 11K | 99.9% | 良好 |
| news-creator | 76K | 0% | 要改善 |
| tag-generator | 40K | 46% | 要改善 |
| db/rag-db/recap-db | 7.4M | 0% | ノイズ |

## 決定

4フェーズに分けて段階的にログ基盤を改善する。

### Phase 1: ノイズ削減

#### 1.1 DBログの完全削除

PostgreSQL系サービス（db, rag-db, recap-db）のログ収集を停止。SQLクエリ断片は可観測性への貢献が低く、ストレージを圧迫していた。

```yaml
# compose/logging.yaml から以下を削除
# - db-logs
# - rag-db-logs
# - recap-db-logs
```

#### 1.2 ANSIエスケープ除去

Meilisearchログ用の専用パーサーを追加し、制御文字を除去。

```rust
// rask-log-forwarder/app/src/parser/services.rs
pub struct MeilisearchParser;

impl MeilisearchParser {
    fn strip_ansi(input: &str) -> String {
        // ESC [ ... m 形式のANSIシーケンスを除去
    }
}
```

### Phase 2: ビジネスコンテキスト追加

#### セマンティック属性の定義

OpenTelemetry Semantic Conventionsに準拠した `alt.` プレフィックス付きの属性を定義。

| 属性キー | 用途 | 対象サービス |
|---------|------|-------------|
| `alt.feed.id` | フィード追跡 | pre-processor, alt-backend |
| `alt.article.id` | 記事追跡 | pre-processor, news-creator |
| `alt.job.id` | ジョブ追跡 | recap-worker, rag-orchestrator |
| `alt.processing.stage` | 処理段階 | 全AI系サービス |
| `alt.ai.pipeline` | AIパイプライン識別 | news-creator, tag-generator |

#### Go サービスへの実装

```go
// utils/logger/context_logger.go
const (
    FeedIDKey          ContextKey = "alt.feed.id"
    ArticleIDKey       ContextKey = "alt.article.id"
    JobIDKey           ContextKey = "alt.job.id"
    ProcessingStageKey ContextKey = "alt.processing.stage"
)

// ヘルパー関数
func WithFeedID(ctx context.Context, feedID string) context.Context
func WithArticleID(ctx context.Context, articleID string) context.Context
```

#### ClickHouseマテリアライズドカラム

```sql
-- 008_add_business_context_columns.sql
ALTER TABLE otel_logs ADD COLUMN IF NOT EXISTS FeedId String
    MATERIALIZED LogAttributes['alt.feed.id'];
ALTER TABLE otel_logs ADD COLUMN IF NOT EXISTS ArticleId String
    MATERIALIZED LogAttributes['alt.article.id'];

-- Bloom filterインデックス追加
ALTER TABLE otel_logs ADD INDEX idx_feed_id FeedId TYPE bloom_filter(0.01);
```

### Phase 3: SLIメトリクス導出

ログからService Level Indicatorsを自動導出するマテリアライズドビューを作成。

```sql
-- 009_create_sli_metrics.sql
CREATE TABLE sli_metrics (
    Timestamp DateTime,
    ServiceName LowCardinality(String),
    Metric LowCardinality(String),
    Value Float64,
    Tags Map(LowCardinality(String), String)
) ENGINE = MergeTree()
TTL Timestamp + INTERVAL 90 DAY DELETE;

-- エラーレート（1分粒度）
CREATE MATERIALIZED VIEW sli_error_rate_mv TO sli_metrics AS
SELECT
    toStartOfMinute(Timestamp) AS Timestamp,
    ServiceName,
    'error_rate' AS Metric,
    countIf(SeverityNumber >= 17) / count() AS Value
FROM otel_logs
GROUP BY ServiceName, toStartOfMinute(Timestamp);
```

### Phase 4: 可観測性強化

#### AIパイプラインダッシュボード

AI系サービス（pre-processor, news-creator, tag-generator）専用のGrafanaダッシュボードを作成。

- AI Pipeline Success Rate（ゲージ）
- AI Service Log Volume（時系列）
- AI Service Error Rate（時系列）
- Recent AI Pipeline Errors（テーブル）

#### アラートルール

```yaml
# ai-pipeline-rules.yaml
- uid: ai-pipeline-high-error-rate
  title: AI Pipeline High Error Rate (> 15%)
  condition: error_rate > 0.15
  for: 5m
  labels:
    severity: warning
    team: ai-platform

- uid: ai-news-creator-no-activity
  title: News Creator No Activity (15 min)
  condition: log_count < 1
  for: 15m
```

## 結果

### 変更ファイル

| ファイル | 変更内容 |
|---------|---------|
| `compose/logging.yaml` | DBログforwarder削除 |
| `rask-log-forwarder/app/src/parser/services.rs` | MeilisearchParser追加 |
| `rask-log-forwarder/app/src/parser/universal.rs` | パーサー登録 |
| `clickhouse/migrations/008_*.sql` | ビジネスコンテキストカラム |
| `clickhouse/migrations/009_*.sql` | SLIメトリクステーブル |
| `pre-processor/app/utils/logger/*.go` | コンテキストキー追加 |
| `alt-backend/app/utils/logger/*.go` | コンテキストキー追加 |
| `observability/grafana/dashboards/ai-pipeline-health.json` | ダッシュボード |
| `observability/alerts/ai-pipeline-rules.yaml` | アラートルール |

### 効果

| 改善項目 | Before | After |
|----------|--------|-------|
| ログノイズ | 74%がDB系 | DB系を完全除去 |
| Meilisearchログ | ANSI混入 | クリーンなテキスト |
| ビジネストラッキング | 不可 | feed_id/article_id追跡可能 |
| SLIメトリクス | なし | エラーレート自動導出 |
| AIパイプライン監視 | 汎用ダッシュボード | 専用ダッシュボード |

### トレードオフ

| PROS | CONS |
|------|------|
| ストレージ使用量74%削減 | DB系ログは完全に失われる |
| クエリパフォーマンス向上 | マイグレーション適用が必要 |
| 意味のある可観測性 | サービスコードの変更が必要 |

## 実装日

2026-01-15

## 関連

- [OpenTelemetry Semantic Conventions](https://opentelemetry.io/docs/concepts/semantic-conventions/)
- [ClickHouse Materialized Views](https://clickhouse.com/docs/en/guides/developer/cascading-materialized-views)
- [Grafana Alerting](https://grafana.com/docs/grafana/latest/alerting/)

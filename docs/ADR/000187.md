# alt-backend 基盤品質・ジョブシステム・パフォーマンス改善

## ADR's STATUS

Accepted (実装完了)

## CONTEXT

### 問題点

alt-backend (Go/Echo/pgx v5) のコード品質・運用安定性に関する複数の課題を、アーキテクチャ・QA・パフォーマンスの3視点で調査し、以下を特定:

| # | カテゴリ | 問題 |
|---|---------|------|
| 1 | エラーハンドリング | `tx.Rollback` の戻り値を文字列比較でチェック (`err.Error() != "tx is closed"`) |
| 2 | 型安全性 | JWT ミドルウェアの context key が plain string（衝突リスク） |
| 3 | 未処理分岐 | scraping policy gateway に空 if ブロック（エラー握り潰し、crawl delay 未強制） |
| 4 | ジョブシステム | `HourlyJobRunner` が `time.Sleep` の無限ループで context 非対応。SIGTERM で停止不可 |
| 5 | DB パフォーマンス | `RegisterMultipleFeeds` が N+1 クエリ（ループ内 SELECT→INSERT/UPDATE） |
| 6 | 設定ハードコード | CORS origins が `routes.go` と `sse_handlers.go` に重複ハードコード |
| 7 | 接続プール | HTTP client の `MaxIdleConnsPerHost` が 10（RSS フェッチに対して低い） |

### 方針

6 フェーズに分けた段階的リファクタリングのうち、Phase 1（基盤品質）・Phase 2（ジョブシステム）・Phase 4（パフォーマンス）・Phase 5（設定外部化）を TDD-first で実施。

## DECISION MAKING

### Phase 1: 基盤品質修正

#### 1-1. tx.Rollback エラーチェックの修正

defer 内の Rollback エラーチェックで `err.Error() != "tx is closed"` という文字列比較を使用していた箇所を、pgx が提供する `errors.Is(err, pgx.ErrTxClosed)` に統一。同時に、エラー返却を `errors.New()` から `fmt.Errorf("...: %w", err)` に変更し、エラーチェーンを保持:

```go
// Before
defer func() {
    if err := tx.Rollback(ctx); err != nil && err.Error() != "tx is closed" {
        logger.Logger.WarnContext(ctx, "Error rolling back transaction", "error", err)
    }
}()

// After
defer func() {
    if rbErr := tx.Rollback(ctx); rbErr != nil && !errors.Is(rbErr, pgx.ErrTxClosed) {
        logger.Logger.WarnContext(ctx, "rollback failed", "error", rbErr)
    }
}()
```

#### 1-2. Context key 型安全性

JWT ミドルウェアの `userContextKey` が plain `string` 型だったため、他パッケージとの context key 衝突リスクがあった。専用の型を導入:

```go
// Before
const userContextKey = "altUser"  // plain string

// After
type jwtContextKey string
const userContextKey jwtContextKey = "altUser"  // typed key
```

`domain/user_context.go` の `contextKey` 型と同様のパターンを適用。

#### 1-3. 空 if ブロック修正

**scraping_policy_gateway.go** の 2 箇所:

1. デフォルトポリシー保存失敗時のエラー握り潰し → `slog.WarnContext` でログ出力
2. crawl delay 未経過時の空ブロック → `return false, nil` で実際にフェッチを拒否

```go
// Before: 何もしない
if timeSinceLastRequest < delay {
    // Rate limit: wait time needed, but for now we'll just log and allow
}

// After: 実際にフェッチを拒否
if timeSinceLastRequest < delay {
    slog.WarnContext(ctx, "crawl delay not elapsed, denying fetch",
        "domain", domainName, "delay", delay, "time_since_last", timeSinceLastRequest)
    return false, nil
}
```

### Phase 2: ジョブシステム刷新

#### JobScheduler の導入

`time.Sleep` ベースの無限ループを廃止し、context-aware な `JobScheduler` を新規実装:

```go
type Job struct {
    Name     string
    Interval time.Duration
    Timeout  time.Duration
    Fn       func(ctx context.Context) error
}

type JobScheduler struct {
    jobs []Job
    wg   sync.WaitGroup
}
```

特徴:
- **context.WithTimeout**: 各ジョブに個別タイムアウトを設定
- **time.Ticker**: `time.Sleep` を排除し、`select` + `ctx.Done()` でキャンセルに即座に応答
- **sync.WaitGroup**: `Shutdown()` で全ジョブの完了を待機
- **即時実行**: Start 時に初回実行を行い、以降は Interval で繰り返し

#### 既存ジョブの単一実行化

3 つのジョブランナーを、自前のループを持たない単一実行関数に変換:

| 関数 | 旧 | 新 |
|------|-----|-----|
| `CollectFeedsJob()` | `HourlyJobRunner` (無限ループ + `time.Sleep`) | 単一実行、エラー返却 |
| `ScrapingPolicyJob()` | `DailyScrapingPolicyJobRunner` (ticker ループ) | 単一実行、エラー返却 |
| `OutboxWorkerJob()` | `OutboxWorkerRunner` (ticker ループ) | 単一実行、エラー返却 |

後方互換のため旧関数名のラッパーも残置。

#### main.go のグレースフルシャットダウン改善

```go
// context.WithCancel で全ジョブにキャンセルを通知可能に
ctx, cancel := context.WithCancel(context.Background())

// Scheduler に全ジョブを登録
scheduler := job.NewJobScheduler()
scheduler.Add(job.Job{Name: "hourly-feed-collector", Interval: 1*time.Hour, Timeout: 30*time.Minute, ...})
scheduler.Add(job.Job{Name: "daily-scraping-policy", Interval: 24*time.Hour, Timeout: 1*time.Hour, ...})
scheduler.Add(job.Job{Name: "outbox-worker", Interval: 5*time.Second, Timeout: 30*time.Second, ...})
scheduler.Start(ctx)

// SIGTERM 受信時
cancel()             // 全ジョブに停止を通知
scheduler.Shutdown() // ジョブ完了を待機
e.Shutdown(...)      // HTTP サーバー停止
```

### Phase 4: パフォーマンス最適化

#### 4-1. RegisterMultipleFeeds のバッチ UPSERT 化

ループ内で SELECT → INSERT/UPDATE を繰り返す N+1 パターンを、`pgx.Batch` + `INSERT ... ON CONFLICT DO UPDATE` による一括処理に置換:

```go
// Before: N 回の SELECT + INSERT/UPDATE
for _, feed := range feeds {
    tx.QueryRow(ctx, "SELECT id FROM feeds WHERE link = $1", feed.Link)
    tx.Exec(ctx, "UPDATE feeds SET ..." ) // or INSERT
}

// After: 1 回のバッチ送信
batch := &pgx.Batch{}
for _, feed := range feeds {
    batch.Queue(upsertQuery, feed.Title, feed.Description, feed.Link, ...)
}
br := tx.SendBatch(ctx, batch)
```

N 件のフィードに対し、DB ラウンドトリップが 2N+1 回 → 3 回に削減。

#### 4-2. HTTP Client 接続プール最適化

同一ドメインへの並行 RSS フェッチに最適化:

| 設定 | 旧 | 新 |
|------|-----|-----|
| `MaxIdleConns` | 100 | 200 |
| `MaxIdleConnsPerHost` | 10 | 50 |

#### 4-3. pgxpool 接続設定の明示化

| 設定 | 旧 | 新 |
|------|-----|-----|
| `MaxConnLifetime` | 30m | 1h |
| `MaxConnIdleTime` | (未設定) | 30m |

### Phase 5: 設定外部化

#### CORS origins の設定外部化

`routes.go` と `sse_handlers.go` に重複ハードコードされていた CORS 許可オリジンを、`config.ServerConfig` に集約:

```go
type ServerConfig struct {
    // ...
    CORSAllowedOrigins []string `env:"CORS_ALLOWED_ORIGINS" default:"http://localhost:3000,http://localhost:80,http://localhost:4173,https://curionoah.com"`
}
```

既存の env loader が `[]string` 型に対応済み（カンマ区切り）のため、環境変数で上書き可能。

## RESULTS, EFFECTS

### 変更ファイル一覧

| ファイル | 変更内容 |
|----------|----------|
| `driver/alt_db/register_feeds_driver.go` | Rollback エラーチェック修正、バッチ UPSERT 化、error wrapping |
| `middleware/jwt_middleware.go` | context key を typed key に変更 |
| `gateway/scraping_policy_gateway/scraping_policy_gateway.go` | 空 if ブロック修正（ログ出力、crawl delay 強制） |
| `job/scheduler.go` | **新規**: context-aware JobScheduler |
| `job/scheduler_test.go` | **新規**: JobScheduler テスト 5 件 |
| `job/job_runner.go` | `CollectFeedsJob()` に変換、`time.Sleep` ループ廃止 |
| `job/daily_scraping_policy_job.go` | `ScrapingPolicyJob()` に変換 |
| `job/outbox_worker.go` | `OutboxWorkerJob()` に変換 |
| `main.go` | `context.WithCancel`、Scheduler 統合、グレースフルシャットダウン改善 |
| `config/config.go` | `CORSAllowedOrigins` フィールド追加 |
| `rest/routes.go` | CORS origins を config から読み込み |
| `rest/sse_handlers.go` | CORS origins を config から読み込み |
| `utils/secure_http_client.go` | `MaxIdleConns`/`MaxIdleConnsPerHost` 引き上げ |
| `driver/alt_db/init.go` | `MaxConnLifetime` 延長、`MaxConnIdleTime` 追加 |

### テスト

| テストファイル | テスト数 |
|---------------|---------|
| `job/scheduler_test.go` (新規) | 5 件 |
| 既存テスト全体 | 全パス |

### 動作確認

- `go vet ./...`: 警告なし
- `go test ./...`: 全パッケージ通過
- `go test -race ./job/... ./driver/alt_db/... ./middleware/... ./rest/... ./config/...`: race condition なし
- コンテナ再ビルド・起動後:
  - `GET /v1/health` → `{"database":"connected","status":"healthy"}`
  - 3 ジョブ（feed collector, scraping policy, outbox worker）が正常起動・実行をログで確認

### PROS

1. **運用安定性**: SIGTERM で全バックグラウンドジョブが確実に停止。`time.Sleep` によるゾンビジョブを排除
2. **DB 負荷軽減**: RegisterMultipleFeeds の DB ラウンドトリップが O(N) → O(1) に
3. **エラー追跡性**: error wrapping により、エラー発生箇所がスタックトレースなしで特定可能
4. **設定柔軟性**: CORS origins を環境変数で変更可能に。コード変更なしでデプロイ先ごとの設定が可能
5. **型安全性**: context key の衝突リスクを排除
6. **crawl delay 強制**: robots.txt の crawl-delay が実際に遵守されるようになった

### CONS, TRADEOFF

1. **後方互換ラッパー**: 旧関数名のラッパーが残るが、main.go 以外からの呼び出しがあるため現時点では削除不可
2. **バッチ UPSERT の制約**: `ON CONFLICT (link)` は `link` カラムに UNIQUE 制約が必要（既存スキーマで設定済み）

## APPENDIX

### 環境変数

| 変数名 | デフォルト | 説明 |
|--------|-----------|------|
| `CORS_ALLOWED_ORIGINS` | `http://localhost:3000,http://localhost:80,http://localhost:4173,https://curionoah.com` | CORS 許可オリジン（カンマ区切り） |
| `DB_MAX_CONN_LIFE` | `1h` | pgxpool 接続の最大生存時間 |

### JobScheduler ジョブ構成

| ジョブ名 | 実行間隔 | タイムアウト |
|----------|----------|-------------|
| `hourly-feed-collector` | 1 時間 | 30 分 |
| `daily-scraping-policy` | 24 時間 | 1 時間 |
| `outbox-worker` | 5 秒 | 30 秒 |

### 関連 ADR

- ADR-000185: news-creator / pre-processor キュー飽和問題の解決

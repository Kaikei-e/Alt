# recap-worker 3-day Recap 自動バッチデーモン化 & 7-day 停止

## ADR's STATUS

Accepted (実装完了)

## CONTEXT

### 問題点

7-day Recap の自動バッチジョブが、記事数の多さに起因する LLM 処理の長時間化により、下流サービスのキュー飽和・タイムアウトで全ジャンル失敗する事象が発生。

- 7-day は対象記事数が多く、LLM 呼び出し回数・待機時間が比例して増大
- 下流サービスのキュー容量を超過し、処理がタイムアウト
- 3-day Recap は記事数が絞られるため安定して完了する実績あり

一方、3-day Recap はこれまで手動トリガー（API 呼び出し）のみで、自動実行の仕組みがなかった。

### 方針

- 7-day 自動バッチを停止し、3-day 自動バッチに切り替え
- `BatchDaemon` を `window_days` パラメータ化し、設定値で制御可能にする
- 中断ジョブのリジューム時も DB に保存された `window_days` を正しく引き継ぐ

## DECISION MAKING

### 設計: BatchDaemon の window_days パラメータ化

`BatchDaemon` にハードコードされていた 7-day 前提のロジックを、設定駆動に変更。

```rust
// Before: 7-day 固定
pub fn spawn_jst_batch_daemon(
    scheduler: Scheduler,
    genres: Vec<String>,
) -> JoinHandle<()>

// After: window_days パラメータ化
pub fn spawn_jst_batch_daemon(
    scheduler: Scheduler,
    genres: Vec<String>,
    window_days: u32,
) -> JoinHandle<()>
```

呼び出し側は `Config::recap_3days_window_days()` から値を取得:

```rust
let recap_window = registry.config().recap_3days_window_days();
let _batch_daemon = spawn_jst_batch_daemon(scheduler.clone(), default_genres, recap_window);
```

### 設計: find_resumable_job の window_days 伝播

中断されたジョブをリジュームする際、DB に保存された `window_days` を取得して `JobContext` に反映。

```sql
-- Before
SELECT job_id, status, last_stage FROM recap_jobs WHERE ...

-- After
SELECT job_id, status, last_stage, window_days FROM recap_jobs WHERE ...
```

返り値の型変更: `(Uuid, JobStatus, Option<String>)` → `(Uuid, JobStatus, Option<String>, u32)`

これにより、3-day ジョブが中断→再起動された場合でも、7-day として誤って再実行されることがない。

### 変更の波及範囲

`find_resumable_job` の返り値型変更は以下のレイヤーに波及:

| レイヤー | ファイル | 変更内容 |
|---------|---------|---------|
| DAO 実装 | `store/dao/job.rs` | SQL クエリ・返り値型 |
| トレイト定義 | `store/dao/traits/job.rs` | トレイト署名 |
| 互換レイヤー | `store/dao/compat.rs` | RecapDao トレイト・blanket impl |
| Unified DAO | `store/dao/impls/unified.rs` | JobDao impl |
| Mock DAO | `store/dao/mock.rs` | テスト用モック |
| Scheduler | `scheduler/jobs.rs` | find_resumable_job ラッパー |
| Daemon | `scheduler/daemon.rs` | リジューム処理・新規ジョブ生成 |
| Type Guard | `scheduler.rs` | 関数ポインタ型 |
| エントリポイント | `main.rs` | デーモン起動引数 |

## RESULTS, EFFECTS

### 変更ファイル一覧

| ファイル | 変更内容 |
|---------|---------|
| `scheduler/daemon.rs` | `BatchDaemon` に `window_days` フィールド追加、`spawn_jst_batch_daemon` にパラメータ追加、ログメッセージ動的化 |
| `store/dao/job.rs` | `find_resumable_job` SQL に `window_days` カラム追加、返り値型変更 |
| `store/dao/traits/job.rs` | `JobDao` トレイト署名更新 |
| `store/dao/compat.rs` | `RecapDao` トレイト・blanket impl 更新 |
| `store/dao/impls/unified.rs` | `UnifiedDao` の `JobDao` impl 更新 |
| `store/dao/mock.rs` | `MockRecapDao` 更新 |
| `scheduler/jobs.rs` | `Scheduler::find_resumable_job` 返り値型更新 |
| `scheduler.rs` | type guard 署名更新 |
| `main.rs` | `recap_3days_window_days()` を使用してデーモン起動 |

### 動作確認

- `cargo test`: 277 テスト全通過
- `cargo build`: ビルド成功
- コンテナ起動後のログで以下を確認:
  - `found resumable job, resuming...` で `resumed_window_days: 7` が表示（前回の 7-day ジョブを正しく認識）
  - 新規スケジュールでは `window_days: 3` でログ出力

### PROS

1. **安定性向上**: 3-day は記事数が少なく、タイムアウトリスクが大幅に低下
2. **設定駆動**: `window_days` がパラメータ化されており、環境変数で容易に変更可能
3. **リジューム整合性**: DB に保存された `window_days` を引き継ぐため、中断→再起動時の不整合がない
4. **後方互換**: `window_days` が NULL の旧ジョブはデフォルト 7 にフォールバック

### CONS, TRADEOFF

1. **カバレッジの縮小**: 3-day ウィンドウでは 3 日より前の記事がカバーされない（7-day に比べて対象範囲が狭い）
2. **7-day の手動運用**: 必要な場合は API 経由で手動トリガーが必要

## APPENDIX

### 環境変数

| 変数名 | デフォルト | 説明 |
|--------|-----------|------|
| `RECAP_3DAYS_WINDOW_DAYS` | 3 | 自動バッチデーモンのウィンドウ日数 |
| `RECAP_WINDOW_DAYS` | 7 | API トリガー時のデフォルトウィンドウ日数 |

### 手動 3-day トリガー

```bash
curl -X POST http://localhost:9005/v1/generate/recaps/3days \
  -H 'Content-Type: application/json' -d '{}'
```

### 関連 ADR

- なし（初回のバッチデーモン window_days パラメータ化）

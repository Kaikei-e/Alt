# ADR-000216: Gemma 3 12B プロンプト最適化 - 日本語化・structured output 強化・Gemma 3 推奨形式対応

## STATUS

Accepted（実装完了・コンテナ再ビルド・ヘルスチェック確認済み）

## CONTEXT

### 背景

rag-orchestrator の LLM バックエンドを Swallow-8B から Gemma 3 12B QAT に移行済み（モデルデプロイ・config 変更・buildOptions 対応は完了）。しかしプロンプトは Swallow-8B 向けの設計がそのまま残っており、Gemma 3 12B の能力を活かしきれていなかった:

1. **8B 向け軽量プロンプト**: Swallow-8B の限られたコンテキストウィンドウ（16K）に合わせて指示を簡素化していたが、Gemma 3 12B はより詳細な指示を処理可能
2. **system ロール非互換**: Gemma 3 は公式には `user` / `model` ロールのみサポート。Ollama が `system` を `<start_of_turn>system` にマッピングするが、公式推奨は user メッセージへの統合
3. **英語プロンプト**: Morning Letter プロンプトが英語で記述されていたが、Gemma 3 は日本語トークナイザが改善されており、日本語プロンプトの方がトークン効率・出力品質ともに優位
4. **ChatStream の format 未適用**: Gemma 3 は Ollama の `format` パラメータによる JSON structured output に対応しているが、ChatStream では Swallow/Llama のみに限定されていた

### 調査に基づく方針

| 調査項目 | 結果 |
|----------|------|
| Gemma 3 ロールサポート | `user` / `model` のみ公式サポート。system は user に埋め込み推奨 |
| Ollama structured output | JSON schema を `format` パラメータで渡すと安定。プロンプト内にもスキーマ記述で精度向上 |
| 日本語プロンプト効率 | Gemma 3 の日本語トークナイザ改善により、日本語プロンプトがトークン効率で優位 |
| 品質向上手法 | ペルソナ設定 + Chain-of-Thought 的な段階的指示で品質向上 |

## DECISION MAKING

### 方針

Gemma 3 12B の能力に合わせてプロンプトを最適化する。3 つの軸で変更:

1. **RAG Answer プロンプト**: system メッセージを user に統合し、12B 向けに詳細指示を追加
2. **Morning Letter プロンプト**: 全文日本語化でトークン効率改善 + 非標準ディレクティブ削除
3. **ChatStream format**: Gemma モデルにも JSON schema による structured output を適用

### RAG Answer プロンプト最適化

Swallow-8B 向けの軽量3セクション構造を、Gemma 3 12B 向けに拡張:

- system / user の2メッセージ構成 → 単一 user メッセージに統合（Gemma 3 推奨形式）
- 回答の最低文字数ガイドライン追加（500文字以上）
- Chain-of-Thought 的な段階的回答構造（概要→詳細→まとめ、詳細に3つのサブセクション）
- JSON 出力形式の明確化（`reason` フィールドを citation にも追加）
- フォールバック条件の日本語での明示

### Morning Letter プロンプト日本語化

- 英語プロンプト → 全文日本語化
- `Reasoning: medium` 等の非標準ディレクティブを削除（Gemma 3 非対応）
- サマリーの最低文字数を明確化（250文字以上）
- JSON 出力形式のサンプルを日本語化（フィールド値の例示）

### ChatStream format 拡張

Gemma 3 が Ollama の `format` パラメータによる structured output に対応しているため、ChatStream のモデル判定条件に `gemma` を追加。

## RESULTS

### 変更内容

| ファイル | 変更内容 |
|---------|---------|
| `internal/usecase/prompt_builder.go` | system + user 2メッセージ → 単一 user メッセージに統合。品質基準（500文字以上）・詳細な回答構造指示・JSON スキーマ例示を追加 |
| `internal/usecase/morning_letter_prompt_builder.go` | 全文日本語化。`Reasoning: medium` 削除。最低文字数（250文字以上）明示。JSON サンプル日本語化 |
| `internal/adapter/rag_augur/ollama_generator.go` | ChatStream の format 適用条件に `gemma` を追加 |
| `internal/usecase/answer_with_rag_usecase_test.go` | mock matcher を単一 user メッセージ対応に更新。新プロンプト内容の assertion 追加 |
| `internal/usecase/morning_letter_prompt_builder_test.go` | 日本語化後の assertion に更新（`ニュースアナリスト`, `最大N個`, `N時間`） |

### テスト結果

| テスト | 結果 |
|--------|------|
| `go test ./internal/... -count=1` | 全パッケージ PASS |

### コンテナ検証

| 検証 | 結果 |
|------|------|
| `docker compose build rag-orchestrator` | 成功 |
| コンテナ起動 | Up（正常起動） |
| ヘルスチェック (`/healthz`) | `{"status":"ok"}` 200 OK |
| レディネスチェック (`/readyz`) | `{"status":"ready"}` 200 OK |
| Connect-RPC サービス登録 | AugurService, MorningLetterService 登録確認 |

## PROS

1. **Gemma 3 ネイティブ形式**: system ロールを使わない user メッセージ統合により、Gemma 3 の公式推奨形式に準拠
2. **回答品質向上**: 500文字以上の品質基準と Chain-of-Thought 的な段階的構造指示により、12B モデルの能力を活用した詳細な回答を誘導
3. **トークン効率**: Morning Letter プロンプトの日本語化により、Gemma 3 の改善された日本語トークナイザを活用。同等の指示をより少ないトークンで表現
4. **structured output 安定性**: ChatStream での JSON schema 適用により、ストリーミング時の JSON 出力安定性が向上
5. **プロンプトと出力言語の一致**: 日本語プロンプト → 日本語出力のパイプラインにより、言語切り替えオーバーヘッドを削減

## CONS, TRADEOFF

1. **単一 user メッセージの制約**: RAG Answer プロンプトを単一メッセージに統合したことで、指示とコンテキストの分離が失われる。将来的に system ロールをネイティブサポートするモデルへの移行時は再分離が必要
2. **日本語プロンプトの汎用性**: Morning Letter プロンプトを全面日本語化したため、他言語での利用には再度ローカライズが必要（現状の利用は日本語のみ）
3. **定量的品質評価は未実施**: プロンプト変更の品質改善は手動確認ベース。定量評価（BLEU/ROUGE 等）は今後の課題

## APPENDIX

### プロンプト構造の変更（RAG Answer）

```
変更前（Swallow-8B 向け）:
  Message[0]: role=system  「リサーチアナリスト + 軽量3セクション + ルール + JSON format」
  Message[1]: role=user    「Context + Query」

変更後（Gemma 3 12B 向け）:
  Message[0]: role=user    「役割 + 品質基準 + 回答構造（詳細サブセクション付き）
                             + 出力形式（JSON スキーマ例示）+ Context + Query」
```

### ChatStream format 適用モデル

```
変更前: swallow, llama
変更後: swallow, llama, gemma
```

# news-creator 要約タスク詰まり診断と修正

## ADR's STATUS

Accepted (実装完了・デプロイ済み)

## CONTEXT

### 問題点

news-creator の要約タスクがキューで **632 秒 (10 分超)** 待機する事象が発生。加えて LLM が空白のみ (60 スペース) のレスポンスを返すケースも観測され、GPU 時間が浪費されていた。

```
pre-processor (Go)  ──LOW──┐
                            │    ┌─────────────────────────────┐
frontend (SSE)     ──HIGH──┤───▶│  HybridPrioritySemaphore    │
                            │    │  total=2, RT予約=1, BE=1    │──▶ Ollama (gemma3-4b)
recap-worker (Rust) ──LOW──┘    │  キュー上限=20              │
                                └─────────────────────────────┘
```

| # | 原因 | 影響 |
|---|------|------|
| 1 | BE スロット 1 つのみ (PARALLEL=2, RT 予約=1) | キュー待ち 632s |
| 2 | LLM 空白レスポンス (60 スペース) | GPU リソース浪費・スロット長時間占有 |
| 3 | タイムアウト不整合 (backend 300s < キュー 632s) | upstream context canceled 後も処理継続 |
| 4 | 優先度昇格 600s で遅すぎ | 昇格前にクライアントタイムアウト |
| 5 | `asyncio.gather()` 一括キュー投入 | キュー飽和 |

### 調査方法

ソースコード、ライブログ、アーキテクチャの 3 方面から並行調査を実施し、5 つの根本原因を特定。

## DECISION MAKING

### 方針

即効性のある設定チューニング (P0) と、コード修正によるキュー管理改善 (P1) を組み合わせて実施。GPU 増設やモデル変更といったインフラ変更は行わず、アプリケーション層のみで対処する。

### P0: 設定値チューニング

#### 優先度昇格しきい値の短縮

`SCHEDULING_PRIORITY_PROMOTION_THRESHOLD_SECONDS` のデフォルトを `600.0` → `120.0` に変更。

| 項目 | 変更前 | 変更後 |
|------|--------|--------|
| デフォルト値 | 600s | 120s |
| 根拠 | — | backend timeout (300s) 前に昇格させ、処理完了の余裕を確保 |

#### キュー深度上限の引き下げ

`MAX_QUEUE_DEPTH` のデフォルトを `20` → `10` に変更。

| 項目 | 変更前 | 変更後 |
|------|--------|--------|
| デフォルト値 | 20 | 10 |
| 根拠 | — | 早期 fail-fast で無駄なキュー待ちを防止 |

両設定を `compose/ai.yaml` にも環境変数として追加し、デプロイ時に明示的に制御可能とした。

### P1-A: キャンセル済みリクエストのキューパージ

**課題**: `acquire()` で `await future` がキャンセルされた場合 (HTTP クライアント切断等)、`QueuedRequest` はヒープに残ったまま。`release()` がスキップするまでキュー深度を無駄に占有していた。

**対策**:

1. `acquire()` の `CancelledError` ハンドラで `_purge_cancelled_from_queues()` を呼び出し、即座にキューから除去
2. 新メソッド `_purge_cancelled_from_queues()` を追加。RT/BE 両キューから `done()` or `cancelled()` な future をフィルタリング

```python
# acquire() 内の CancelledError ハンドラ
except asyncio.CancelledError:
    if not future.done():
        future.cancel()
    async with self._lock:
        self._purge_cancelled_from_queues()
    raise
```

### P1-B: `_apply_aging()` でのキューパージ

**課題**: `release()` → `_apply_aging()` のサイクルで BE キューを走査する際、既にキャンセル済みの future が残っていると不要な優先度計算やプロモーション処理が発生していた。

**対策**: `_apply_aging()` の走査ループで `future.done()` or `future.cancelled()` なエントリをスキップし、再ヒープ化対象から除外。パージ数をログ出力。

### P1-C: 空レスポンス時の早期スロット解放

**課題**: LLM が空白のみのレスポンスを返した場合、リトライループ内でスロットを保持したまま全リトライを消費していた。モデルが一時的に不良状態の場合、空白→リトライ→空白→リトライの繰り返しで長時間スロットを占有。

**対策**: 連続空レスポンスカウンタ `consecutive_empty_count` を導入。2 回連続で空白レスポンス (stripped length < 10) を検出した場合、`RuntimeError` を raise してスロットを即座に解放。

```python
if len(raw_text_stripped) < 10:
    consecutive_empty_count += 1
    if consecutive_empty_count >= 2:
        raise RuntimeError(
            f"LLM returned empty/whitespace summary {consecutive_empty_count} "
            f"times consecutively"
        )
```

非空レスポンスが返ってきた場合はカウンタをリセットするため、一時的な空白が 1 回だけの場合は既存のリトライロジックが正常に機能する。

### P1-D: Map-Reduce 並列度制限

**課題**: `recap_summary_usecase.py` の Map phase (`_generate_hierarchical_summary`) および batch 処理 (`generate_batch_summary`) で `asyncio.gather(*tasks)` により全タスクを一括投入。クラスタ数が多い場合にキューが飽和し、`QueueFullError` や長時間待機の原因となっていた。

**対策**: `asyncio.Semaphore(min(3, ollama_request_concurrency))` で同時投入数を制限。

```python
map_semaphore = asyncio.Semaphore(
    min(3, self.config.ollama_request_concurrency)
)

async def throttled_chunk_summary(chunk_idx, chunk_clusters):
    async with map_semaphore:
        return await self._generate_chunk_summary(...)
```

batch 処理にも同様のセマフォを適用。キューへの投入を段階的にすることで、キュー深度のスパイクを防止。

## RESULTS, EFFECTS

### 変更ファイル一覧

| ファイル | 変更内容 |
|---------|---------|
| `news-creator/app/news_creator/config/config.py` | デフォルト値変更 (promotion 600→120, queue 20→10) |
| `news-creator/app/news_creator/gateway/hybrid_priority_semaphore.py` | キャンセルパージ (`_purge_cancelled_from_queues`), aging パージ |
| `news-creator/app/news_creator/usecase/summarize_usecase.py` | 空レスポンス連続検知・早期打ち切り |
| `news-creator/app/news_creator/usecase/recap_summary_usecase.py` | Map/batch 並列度セマフォ制限 |
| `compose/ai.yaml` | 環境変数追加 (promotion threshold, queue depth) |
| `tests/usecase/test_recap_summary_usecase.py` | Mock config に `ollama_request_concurrency` 追加 |

### PROS

- **テスト全パス**: 68 テスト (semaphore 50 + summarize 3 + recap_summary 15) が全パス。既存テストの破壊なし
- **設定変更即時反映**: デプロイ後のログで `priority_promotion_threshold: 120.0`, `max_queue_depth: 10` を確認
- **キュー状態監視**: `/queue/status` エンドポイントで `max_queue_depth: 10` が反映済み
- **キャンセル伝播の改善**: HTTP クライアント切断時にキューからのパージが即座に行われ、キュー深度の膨張を防止
- **空レスポンス対策**: 2 回連続空白で早期打ち切りにより、モデル不良時のスロット占有を最小化
- **キュー飽和防止**: Map-Reduce と batch の並列度制限で、大量タスク一括投入によるキュー溢れを防止
- **コンテナ稼働確認**: リビルド後に `news-creator` が healthy 状態で起動確認済み

### CONS, TRADEOFF

- **スループット影響**: Map-Reduce の並列度制限 (最大 3) により、クラスタ数が多い場合の理論上の最大スループットは低下する。ただし実環境では GPU スロットが 2 のため実質的な影響はない
- **キュー深度 10 への削減**: 高負荷時に `QueueFullError` が従来より早く発生する。fail-fast 戦略として意図的だが、burst traffic に対する耐性は低下する
- **根本解決ではない**: GPU スロット数 (OLLAMA_NUM_PARALLEL=2) が根本的なボトルネック。VRAM 増設やモデルの軽量化なしにはスループットの大幅改善は困難

### 検証方法

```bash
# テスト実行
SERVICE_SECRET=test-secret uv run pytest tests/gateway/test_hybrid_priority_semaphore.py \
  tests/usecase/test_summarize_usecase.py \
  tests/usecase/test_recap_summary_usecase.py -v

# キュー状態確認
curl http://localhost:11434/queue/status

# 設定値確認 (起動ログ)
docker compose -f compose/compose.yaml -p alt logs news-creator --since 5m | \
  grep -E 'priority_promotion|max_queue_depth'
```

# pre-processor に最大コンテンツ長制限を追加

## ステータス

採択（Accepted）

## コンテキスト

### 背景

pre-processor が非常に大きな記事（188KB超）を news-creator に送信した際、LLM 処理がタイムアウトし、同じ記事が繰り返しリトライされる問題が発生した。

### 問題

1. 巨大な記事（188KB = 約187,000文字）が要約キューに入る
2. news-creator の階層的要約でも処理時間が 300 秒タイムアウトを超過
3. 同じ記事が無限にリトライされ、GPU リソースを浪費
4. 他の記事の処理がブロックされる

### 既存の制限

| レイヤー | 制限種別 | 値 |
|---------|---------|-----|
| pre-processor | 最小 | 100 文字 |
| pre-processor | 最大 | **なし** |
| news-creator | 階層化閾値 | 25,000 文字 |
| news-creator | トランケーション | 60,000 文字 |

### ベストプラクティス調査

LLM の大規模テキスト処理に関するベストプラクティスを調査した結果：

- **コンテキストウィンドウの実用的上限**: 32K トークンが「高速・低 VRAM」の推奨値
- **メモリ考慮**: 大きなコンテキストは VRAM 消費増加と処理速度低下を招く
- **トークン換算**: 100KB ≈ 25K トークン（日本語）

参考:
- [Agenta - Context Length Management](https://agenta.ai/blog/top-6-techniques-to-manage-context-length-in-llms)
- [Ollama Context Length Docs](https://docs.ollama.com/context-length)

## 決定

pre-processor に 100KB（100,000 文字）の最大コンテンツ長制限を追加する。

### 制限値の根拠

| トークン | 文字数（日本語） | 実用性 |
|---------|----------------|-------|
| 8K | ~20,000 | 高速・安定 |
| 16K | ~40,000 | 標準 |
| 32K | ~80,000 | 推奨上限 |
| **25K** | **~100,000** | **採用値** |

100KB は約 25K トークンに相当し、32K コンテキストウィンドウに余裕を持って収まる。

### 実装内容

#### 1. エラー定義追加

```go
// domain/errors.go
var ErrContentTooLong = errors.New("content too long for summarization")
```

#### 2. 最大長チェック追加

```go
// driver/summarizer_api.go
const maxContentLength = 100_000 // 100KB

if extractedLength > maxContentLength {
    logger.Info("Skipping summarization: content too long after extraction",
        "article_id", article.ID,
        "extracted_length", extractedLength,
        "max_allowed", maxContentLength)
    return nil, ErrContentTooLong
}
```

#### 3. プレースホルダー処理

```go
// service/article_summarizer.go
if errors.Is(err, domain.ErrContentTooLong) {
    placeholderSummary := &models.ArticleSummary{
        ArticleID:       article.ID,
        SummaryJapanese: "本文が長すぎるため要約できませんでした。",
    }
    // 処理済みとして保存
}
```

## 結果

### 変更ファイル

| ファイル | 変更内容 |
|---------|---------|
| `pre-processor/app/domain/errors.go` | `ErrContentTooLong` 追加 |
| `pre-processor/app/driver/summarizer_api.go` | 100KB 制限チェック（2 箇所） |
| `pre-processor/app/service/article_summarizer.go` | プレースホルダー処理追加 |

### 動作確認

```
Skipping summarization: content too long after extraction
extracted_length: 187686, max_allowed: 100000
article content too long, saving placeholder summary
processed: 1, success: 1, errors: 0
```

### 効果

- 巨大記事は即座にスキップされ、無限リトライが解消
- プレースホルダーサマリーにより、ユーザーには「長すぎる」旨を表示
- 処理済みとしてカウントされ、キューが正常に進行

### トレードオフ

| PROS | CONS |
|------|------|
| タイムアウトによる無限リトライ防止 | 100KB 超の記事は要約されない |
| GPU リソースの効率的利用 | 巨大記事のユーザー体験低下 |
| 他の記事の処理がブロックされない | 将来的に制限値の見直しが必要な可能性 |

## 実装日

2026-01-15

## 関連

- [Ollama Context Length Documentation](https://docs.ollama.com/context-length)
- [Agenta - Top Techniques to Manage Context Length in LLMs](https://agenta.ai/blog/top-6-techniques-to-manage-context-length-in-llms)

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ include "clickhouse.fullname" . }}
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "clickhouse.labels" . | nindent 4 }}
  {{- with .Values.commonAnnotations }}
  annotations:
    {{- toYaml . | nindent 4 }}
  {{- end }}
spec:
  serviceName: {{ include "clickhouse.fullname" . }}
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      {{- include "clickhouse.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "clickhouse.selectorLabels" . | nindent 8 }}
        {{- with .Values.podLabels }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
      annotations:
        checksum/config: {{ include (print $.Template.BasePath "/configmap.yaml") . | sha256sum }}
        {{- with .Values.podAnnotations }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccountName: {{ include "clickhouse.serviceAccountName" . }}
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      # INCIDENT 37 FIX: Pod Security Standards compliant initContainer for lost+found removal + directories
      initContainers:
        - name: clickhouse-lost-found-cleanup-v37
          image: alpine:3.18
          command:
            - /bin/sh
            - -c
            - |
              echo "=== INCIDENT 37: ClickHouse Complete Lost+Found Cleanup + Directory Creation ==="
              echo "SOLUTION: Complete PVC cleanup + Pod Security Standards compliant initContainer"
              
              # PHASE 1: Complete directory analysis
              echo "Phase 1: Pre-cleanup directory analysis..."
              cd /var/lib/clickhouse
              echo "Root directory contents:"
              ls -la || true
              echo "Hidden files and lost+found detection:"
              find . -name "lost+found" -o -name ".*" 2>/dev/null || true
              
              # PHASE 2: Complete lost+found and artifacts removal
              echo "Phase 2: Complete lost+found and artifacts cleanup..."
              # Critical: Remove lost+found directory (PVC artifact)
              rm -rf lost+found
              # Remove any hidden directories that may cause issues
              rm -rf .* 2>/dev/null || true
              
              # PHASE 3: Create required ClickHouse directories
              echo "Phase 3: ClickHouse required directories creation..."
              mkdir -p /var/lib/clickhouse/logs
              mkdir -p /var/lib/clickhouse/user_files  
              mkdir -p /var/lib/clickhouse/format_schemas
              mkdir -p /var/lib/clickhouse/tmp
              
              # PHASE 4: Set proper ownership for ClickHouse user (101:101)
              echo "Phase 4: Setting proper ownership for ClickHouse user..."
              chown -R 101:101 /var/lib/clickhouse
              chmod -R 755 /var/lib/clickhouse
              
              echo "=== INCIDENT 37 CLICKHOUSE CLEANUP COMPLETED ==="
              echo "âœ… Lost+found directory completely removed"
              echo "âœ… Required ClickHouse directories created"
              echo "âœ… Proper ownership (101:101) applied"
              echo "Final directory state:"
              ls -la /var/lib/clickhouse/ || true
              echo "ðŸš€ Ready for ClickHouse v24.8-alpine startup"
          volumeMounts:
            - name: data
              mountPath: /var/lib/clickhouse
          securityContext:
            runAsUser: 0  # Required for chown operations - Pod Security Standards baseline compliant
            runAsNonRoot: false
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
              add:
                - CHOWN
                - FOWNER
            seccompProfile:
              type: RuntimeDefault
      containers:
        - name: clickhouse
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          ports:
            - name: http
              containerPort: 8123
              protocol: TCP
            - name: tcp
              containerPort: 9000
              protocol: TCP
            - name: mysql
              containerPort: 9004
              protocol: TCP
            - name: postgresql
              containerPort: 9005
              protocol: TCP
            - name: interserver
              containerPort: 9009
              protocol: TCP
          env:
            - name: CLICKHOUSE_DB
              value: {{ .Values.auth.database | quote }}
            - name: CLICKHOUSE_USER
              value: {{ .Values.auth.username | quote }}
            - name: CLICKHOUSE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.auth.existingSecret | default (printf "%s-secret" (include "clickhouse.fullname" .)) }}
                  key: {{ .Values.auth.secretKeys.password }}
            - name: CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT
              value: "1"
            {{- if .Values.ssl.enabled }}
            - name: CLICKHOUSE_SSL_CERT_FILE
              value: /ssl/server.crt
            - name: CLICKHOUSE_SSL_KEY_FILE
              value: /ssl/server.key
            - name: CLICKHOUSE_SSL_CA_FILE
              value: /ssl/ca.crt
            {{- end }}
            {{- with .Values.extraEnv }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
          volumeMounts:
            - name: data
              mountPath: {{ include "clickhouse.dataDir" . }}
              # PHASE B: Remove problematic subPath - initContainer creates all directories
            - name: config
              mountPath: /etc/clickhouse-server/config.xml
              subPath: config.xml
              readOnly: true
            - name: config
              mountPath: /etc/clickhouse-server/users.xml
              subPath: users.xml
              readOnly: true
            {{- if .Values.ssl.enabled }}
            - name: ssl-data
              mountPath: /ssl
              readOnly: true
            {{- end }}
            {{- with .Values.extraVolumeMounts }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
          livenessProbe:
            httpGet:
              path: /ping
              port: http
              scheme: HTTP  # Force HTTP for health checks (SSL for client connections)
            initialDelaySeconds: {{ .Values.livenessProbe.initialDelaySeconds | default 60 }}
            periodSeconds: {{ .Values.livenessProbe.periodSeconds | default 30 }}
            timeoutSeconds: {{ .Values.livenessProbe.timeoutSeconds | default 10 }}
            failureThreshold: {{ .Values.livenessProbe.failureThreshold | default 5 }}
          readinessProbe:
            httpGet:
              path: /ping
              port: http
              scheme: HTTP  # Force HTTP for health checks (SSL for client connections)
            initialDelaySeconds: {{ .Values.readinessProbe.initialDelaySeconds | default 30 }}
            periodSeconds: {{ .Values.readinessProbe.periodSeconds | default 15 }}
            timeoutSeconds: {{ .Values.readinessProbe.timeoutSeconds | default 5 }}
            failureThreshold: {{ .Values.readinessProbe.failureThreshold | default 8 }}
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
          securityContext:
            {{- toYaml .Values.securityContext | nindent 12 }}
      volumes:
        - name: config
          configMap:
            name: {{ include "clickhouse.fullname" . }}-config
        # WEB RESEARCH: Removed separate logs volume - using data PVC subdirectory
        {{- if .Values.ssl.enabled }}
        - name: ssl-certs
          secret:
            secretName: {{ .Values.ssl.secretName }}
            defaultMode: 0600
        - name: ssl-data
          emptyDir: {}
        {{- end }}
        {{- with .Values.extraVolumes }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
  volumeClaimTemplates:
    - metadata:
        name: data
        labels:
          {{- include "clickhouse.selectorLabels" . | nindent 10 }}
      spec:
        accessModes:
          {{- range .Values.persistence.data.accessModes }}
          - {{ . | quote }}
          {{- end }}
        resources:
          requests:
            storage: {{ .Values.persistence.data.size | quote }}
        {{- if .Values.persistence.data.storageClass }}
        {{- if (eq "-" .Values.persistence.data.storageClass) }}
        storageClassName: ""
        {{- else }}
        storageClassName: {{ .Values.persistence.data.storageClass | quote }}
        {{- end }}
        {{- end }}
    {{- if .Values.persistence.logs.enabled }}
    - metadata:
        name: logs
        labels:
          {{- include "clickhouse.selectorLabels" . | nindent 10 }}
      spec:
        accessModes:
          {{- range .Values.persistence.logs.accessModes }}
          - {{ . | quote }}
          {{- end }}
        resources:
          requests:
            storage: {{ .Values.persistence.logs.size | quote }}
        {{- if .Values.persistence.logs.storageClass }}
        {{- if (eq "-" .Values.persistence.logs.storageClass) }}
        storageClassName: ""
        {{- else }}
        storageClassName: {{ .Values.persistence.logs.storageClass | quote }}
        {{- end }}
        {{- end }}
    {{- end }}
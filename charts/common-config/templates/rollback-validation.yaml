{{- if .Values.rollback.enabled }}
# Job for rollback validation
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ include "common-config.fullname" . }}-rollback-validation
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "common-config.labels" . | nindent 4 }}
    app.kubernetes.io/component: rollback
  annotations:
    "helm.sh/hook": post-rollback
    "helm.sh/hook-weight": "1"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  ttlSecondsAfterFinished: {{ .Values.rollback.ttlSecondsAfterFinished | default 300 }}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: rollback-validation
        app.kubernetes.io/instance: {{ .Release.Name }}
    spec:
      restartPolicy: Never
      serviceAccountName: {{ include "common-config.serviceAccountName" . }}
      containers:
        - name: rollback-validator
          image: {{ .Values.rollback.image.repository }}:{{ .Values.rollback.image.tag }}
          imagePullPolicy: {{ .Values.rollback.image.pullPolicy }}
          command:
            - /bin/sh
            - -c
            - |
              echo "ðŸ”„ Starting rollback validation for release: {{ .Release.Name }}"
              echo "ðŸ“ Namespace: {{ .Release.Namespace }}"
              echo "ðŸ“¦ Chart: {{ .Chart.Name }}-{{ .Chart.Version }}"
              
              # Wait for rollback to stabilize
              sleep {{ .Values.rollback.stabilizationDelay | default 30 }}
              
              # Check deployment status
              echo "ðŸ” Checking deployment status..."
              kubectl rollout status deployment/{{ include "common-config.fullname" . }} -n {{ .Release.Namespace }} --timeout=300s
              
              # Verify pods are running
              echo "ðŸ” Verifying pods are healthy..."
              READY_PODS=$(kubectl get pods -n {{ .Release.Namespace }} -l app.kubernetes.io/instance={{ .Release.Name }} -o jsonpath='{.items[?(@.status.phase=="Running")].metadata.name}' | wc -w)
              TOTAL_PODS=$(kubectl get pods -n {{ .Release.Namespace }} -l app.kubernetes.io/instance={{ .Release.Name }} -o jsonpath='{.items[*].metadata.name}' | wc -w)
              
              echo "ðŸ“Š Pods ready: $READY_PODS/$TOTAL_PODS"
              
              if [ "$READY_PODS" -eq "$TOTAL_PODS" ] && [ "$TOTAL_PODS" -gt 0 ]; then
                echo "âœ… Rollback validation successful"
                
                # Optional: Run health checks
                {{- if .Values.rollback.healthCheck.enabled }}
                echo "ðŸ©º Running health checks..."
                for endpoint in {{ .Values.rollback.healthCheck.endpoints | join " " }}; do
                  echo "Checking: $endpoint"
                  kubectl run health-check-$RANDOM --image=curlimages/curl:8.4.0 --rm -i --restart=Never -- \
                    curl -f --max-time 10 "$endpoint" || echo "âš ï¸ Health check failed for $endpoint"
                done
                {{- end }}
                
                # Send notification
                {{- if .Values.rollback.notifications.enabled }}
                echo "ðŸ“¢ Sending rollback success notification..."
                kubectl run notification-$RANDOM --image=curlimages/curl:8.4.0 --rm -i --restart=Never -- \
                  curl -X POST "{{ .Values.rollback.notifications.webhook }}" \
                  -H "Content-Type: application/json" \
                  -d '{"text":"âœ… Rollback successful for {{ .Release.Name }} in {{ .Release.Namespace }}"}'
                {{- end }}
                
              else
                echo "âŒ Rollback validation failed"
                exit 1
              fi
          resources:
            {{- toYaml .Values.rollback.resources | nindent 12 }}
          env:
            - name: NAMESPACE
              value: {{ .Release.Namespace }}
            - name: RELEASE_NAME
              value: {{ .Release.Name }}
---
# ConfigMap for rollback scripts
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "common-config.fullname" . }}-rollback-scripts
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "common-config.labels" . | nindent 4 }}
data:
  pre-rollback-backup.sh: |
    #!/bin/bash
    # Pre-rollback backup script
    echo "ðŸ“¦ Creating pre-rollback backup..."
    
    # Backup current release info
    helm get values {{ .Release.Name }} -n {{ .Release.Namespace }} > /tmp/pre-rollback-values.yaml
    helm get manifest {{ .Release.Name }} -n {{ .Release.Namespace }} > /tmp/pre-rollback-manifest.yaml
    
    # Store in ConfigMap for recovery
    kubectl create configmap {{ .Release.Name }}-backup-$(date +%Y%m%d%H%M%S) \
      --from-file=/tmp/pre-rollback-values.yaml \
      --from-file=/tmp/pre-rollback-manifest.yaml \
      -n {{ .Release.Namespace }} || true
    
    echo "âœ… Backup completed"
  
  post-rollback-cleanup.sh: |
    #!/bin/bash
    # Post-rollback cleanup script
    echo "ðŸ§¹ Starting post-rollback cleanup..."
    
    # Remove failed pods
    kubectl delete pods -n {{ .Release.Namespace }} --field-selector=status.phase=Failed || true
    
    # Clean up old backup ConfigMaps (keep last 5)
    kubectl get configmap -n {{ .Release.Namespace }} -l app.kubernetes.io/instance={{ .Release.Name }} \
      --sort-by=.metadata.creationTimestamp -o name | head -n -5 | xargs kubectl delete || true
    
    echo "âœ… Cleanup completed"
{{- end }}